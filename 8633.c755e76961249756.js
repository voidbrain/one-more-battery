(()=>{var I,on={18633:(I,Q,l)=>{"use strict";var y=l(10467),r=l(41653),f=(l(62914),l(10222),l(50531),l(15293),l(91584),l(91806),l(22919)),nt=(l(40083),l(31542),l(48631)),K=l(42804),N=l(67165),m=l(42946),z=l(7257),C=l(59352),c=l(71936);r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,e){t=(0,c.un)(t);let s=(0,r.VVh)(t);return null!=this.maxValue&&(s=(0,r.zQh)(s,0,this.maxValue)),s}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}return i.className="ReLU",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=(0,c.un)(t);return(0,r.H8d)(s,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}return i.className="LeakyReLU",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=(0,z.Fe)(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=(0,C.Bm)(t.alphaRegularizer),this.alphaConstraint=(0,N.YZ)(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!=typeof t.sharedAxes)throw new m.Qp(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);this.sharedAxes=[t.sharedAxes]}}build(t){const e=(t=(0,c.U$)(t)).slice(1);if(null!=this.sharedAxes)for(const a of this.sharedAxes)e[a-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const s={};if(null!=this.sharedAxes)for(let a=1;a<t.length;++a)s[a]=t[a];this.inputSpec=[new f.eO({ndim:t.length,axes:s})],this.built=!0}call(t,e){return t=(0,c.un)(t),(0,r.NsG)(t,this.alpha.read())}getConfig(){const t={alphaInitializer:(0,z.zo)(this.alphaInitializer),alphaRegularizer:(0,C.R9)(this.alphaRegularizer),alphaConstraint:(0,N.uH)(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}return i.className="PReLU",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new m.EH(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const s=(0,c.un)(t);return(0,r.Pqc)(s)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}return i.className="ELU",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,e){const s=(0,c.un)(t);return(0,r.lKK)(s,(0,r.wgE)((0,r.rhj)(s,this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}return i.className="ThresholdedReLU",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new K.rF).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,e){return(0,r.DZQ)(()=>{let s=(0,c.un)(t);const a=e.mask;if(null!=a){const o=(0,r.lKK)((0,r.jbE)((0,r.SaS)(s.shape),(0,r.wgE)(a,s.dtype)),(0,r.d_2)(-1e9));s=(0,r.WQq)(s,o)}return this.axis instanceof Array?this.axis.length>1?(0,r.oNF)((0,r.jbE)(s,(0,r.VZ)(s,this.axis,!0))):this.softmax(s,this.axis[0]):this.softmax(s,this.axis)})}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Softmax",i})());var rt=l(17513),x=l(99198),P=l(9980),Y=l(51367),D=l(24503);function h(i,n){return(0,r.DZQ)(()=>((0,P.uM)(n),"channelsFirst"===n?r.mgz(i,[0,2,3,1]):i))}function v(i,n){return(0,r.DZQ)(()=>((0,P.uM)(n),"channelsFirst"===n?r.mgz(i,[0,2,3,4,1]):i))}function ut(i,n,t,e=[1,1],s="valid",a,o,u=null){return(0,r.DZQ)(()=>{if(null==a&&(a=(0,rt.VI)()),(0,P.uM)(a),3!==i.rank&&4!==i.rank)throw new m.Qp(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${i.rank}.`);if(3!==n.rank&&4!==n.rank)throw new m.Qp(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${i.rank}.`);let p=h(i,a);if("causal"===s)throw new m.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return p=r.cZk.conv2d({x:p,filter:n,strides:e,pad:"same"===s?"same":"valid",dilations:o,dataFormat:"NHWC",bias:t,activation:u}),"channelsFirst"===a&&(p=r.mgz(p,[0,3,1,2])),p})}class wt extends f.Wd{constructor(n,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",wt.verifyArgs(t),this.rank=n,D.oo(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new m.EH(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=(0,Y.J)(t.kernelSize,n,"kernelSize"),this.strides=(0,Y.J)(null==t.strides?1:t.strides,n,"strides"),this.padding=null==t.padding?"valid":t.padding,(0,P.tB)(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,P.uM)(this.dataFormat),this.activation=(0,K.b_)(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=(0,z.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=(0,N.YZ)(t.biasConstraint),this.biasRegularizer=(0,C.Bm)(t.biasRegularizer),this.activityRegularizer=(0,C.Bm)(t.activityRegularizer),this.dilationRate=(0,Y.J)(null==t.dilationRate?1:t.dilationRate,n,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new m.Qp(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new m.Qp(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new m.Qp(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(n){if(D.vA("kernelSize"in n,"required key 'kernelSize' not in config"),"number"!=typeof n.kernelSize&&!D.HP(n.kernelSize,"number",1,3))throw new m.Qp(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(n.kernelSize)}.`)}getConfig(){const n={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:(0,K.Bu)(this.activation),useBias:this.useBias,biasInitializer:(0,z.zo)(this.biasInitializer),biasRegularizer:(0,C.R9)(this.biasRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),biasConstraint:(0,N.uH)(this.biasConstraint)},t=super.getConfig();return Object.assign(n,t),n}}class Ct extends wt{constructor(n,t){super(n,t),this.kernel=null,Ct.verifyArgs(t),this.filters=t.filters,D.oo(this.filters,"filters"),this.kernelInitializer=(0,z.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=(0,N.YZ)(t.kernelConstraint),this.kernelRegularizer=(0,C.Bm)(t.kernelRegularizer)}build(n){n=(0,c.U$)(n);const t="channelsFirst"===this.dataFormat?1:n.length-1;if(null==n[t])throw new m.Qp(`The channel dimension of the input should be defined. Found ${n[t]}`);const e=n[t],s=this.kernelSize.concat([e,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:e}}],this.built=!0}call(n,t){return(0,r.DZQ)(()=>{let e;n=(0,c.un)(n);const s=null==this.bias?null:this.bias.read(),a=D.Cd(this.activation.getClassName());if(null!=a&&2===this.rank)e=ut(n,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate,a);else{if(1===this.rank)e=function j(i,n,t,e=1,s="valid",a,o=1){return(0,r.DZQ)(()=>{if(null==a&&(a=(0,rt.VI)()),(0,P.uM)(a),3!==i.shape.length)throw new m.Qp(`The input of a conv1dWithBias operation should be 3, but is ${i.shape.length} instead.`);if(3!==n.shape.length)throw new m.Qp(`The kernel for a conv1dWithBias operation should be 3, but is ${n.shape.length} instead`);if(null!=t&&1!==t.shape.length)throw new m.Qp(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);if("channelsFirst"===a&&(i=r.mgz(i,[0,2,1])),"causal"===s)throw new m.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let u=r.kA9(i,n,e,"same"===s?"same":"valid","NWC",o);return null!=t&&(u=x.ni(u,t)),u})}(n,this.kernel.read(),s,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=ut(n,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new m.EH("convolutions greater than 3D are not implemented yet.");e=function Bt(i,n,t,e=[1,1,1],s="valid",a,o){return(0,r.DZQ)(()=>{if(null==a&&(a=(0,rt.VI)()),(0,P.uM)(a),4!==i.rank&&5!==i.rank)throw new m.Qp(`conv3dWithBias expects input to be of rank 4 or 5, but received ${i.rank}.`);if(4!==n.rank&&5!==n.rank)throw new m.Qp(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${i.rank}.`);let u=v(i,a);if("causal"===s)throw new m.EH("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return u=r.IPL(u,n,e,"same"===s?"same":"valid","NDHWC",o),null!=t&&(u=x.ni(u,t)),"channelsFirst"===a&&(u=r.mgz(u,[0,4,1,2,3])),u})}(n,this.kernel.read(),s,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e})}computeOutputShape(n){n=(0,c.U$)(n);const t=[],e="channelsLast"===this.dataFormat?n.slice(1,n.length-1):n.slice(2);for(let a=0;a<e.length;++a){const o=(0,Y.Ol)(e[a],this.kernelSize[a],this.padding,this.strides[a],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[a]);t.push(o)}let s=[n[0]];return"channelsLast"===this.dataFormat?(s=s.concat(t),s.push(this.filters)):(s.push(this.filters),s=s.concat(t)),s}getConfig(){const n={filters:this.filters,kernelInitializer:(0,z.zo)(this.kernelInitializer),kernelRegularizer:(0,C.R9)(this.kernelRegularizer),kernelConstraint:(0,N.uH)(this.kernelConstraint)},t=super.getConfig();return Object.assign(n,t),n}static verifyArgs(n){if(!("filters"in n)||"number"!=typeof n.filters||n.filters<1)throw new m.Qp(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(n.filters)}`)}}let Pt=(()=>{class i extends Ct{constructor(t){super(2,t),i.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!D.HP(t.kernelSize,"number",1,2))throw new m.Qp(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}return i.className="Conv2D",i})();r.JFn.registerClass(Pt);let Wt=(()=>{class i extends Ct{constructor(t){super(3,t),i.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new m.Qp(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}return i.className="Conv3D",i})();r.JFn.registerClass(Wt);let Ht=(()=>{class i extends Pt{constructor(t){if(super(t),this.inputSpec=[new f.eO({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new m.Qp(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(4!==(t=(0,c.U$)(t)).length)throw new m.Qp("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new m.Qp("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],a=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",a,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new f.eO({ndim:4,axes:{[e]:s}})],this.built=!0}call(t,e){return r.DZQ(()=>{let s=(0,c.un)(t);if(4!==s.shape.length)throw new m.Qp(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);const a=s.shape;let u,p;"channelsFirst"===this.dataFormat?(u=2,p=3):(u=1,p=2);const b=a[p],k=this.kernelSize[1],_=this.strides[1],J=[a[0],(0,Y.mW)(a[u],this.strides[0],this.kernelSize[0],this.padding),(0,Y.mW)(b,_,k,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(s=r.mgz(s,[0,2,3,1]));let at=r.wX9(s,this.kernel.read(),J,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(at=r.mgz(at,[0,3,1,2])),null!=this.bias&&(at=x.ni(at,this.bias.read(),this.dataFormat)),null!=this.activation&&(at=this.activation.apply(at)),at})}computeOutputShape(t){const e=(t=(0,c.U$)(t)).slice();let s,a,o;"channelsFirst"===this.dataFormat?(s=1,a=2,o=3):(s=3,a=1,o=2);const u=this.kernelSize[0],p=this.kernelSize[1],g=this.strides[0],b=this.strides[1];return e[s]=this.filters,e[a]=(0,Y.mW)(e[a],g,u,this.padding),e[o]=(0,Y.mW)(e[o],b,p,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}return i.className="Conv2DTranspose",i})();r.JFn.registerClass(Ht);let Gt=(()=>{class i extends Wt{constructor(t){if(super(t),this.inputSpec=[new f.eO({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new m.Qp(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(5!==(t=(0,c.U$)(t)).length)throw new m.Qp("Input should have rank 5; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new m.Qp("The channel dimension of the inputs should be defined. Found `None`.");const s=t[e],a=this.kernelSize.concat([this.filters,s]);this.kernel=this.addWeight("kernel",a,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new f.eO({ndim:5,axes:{[e]:s}})],this.built=!0}call(t,e){return r.DZQ(()=>{let s=(0,c.un)(t);if(5!==s.shape.length)throw new m.Qp(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${s.shape.length}`);const a=s.shape;let u,p,g;"channelsFirst"===this.dataFormat?(g=2,u=3,p=4):(g=1,u=2,p=3);const E=a[u],k=a[p],_=this.kernelSize[1],tt=this.kernelSize[2],J=this.strides[1],at=this.strides[2],dt=[a[0],(0,Y.mW)(a[g],this.strides[0],this.kernelSize[0],this.padding),(0,Y.mW)(E,J,_,this.padding),(0,Y.mW)(k,at,tt,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(s=r.mgz(s,[0,2,3,4,1]));let gt=r.jIJ(s,this.kernel.read(),dt,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(gt=r.mgz(gt,[0,4,1,2,3])),null!==this.bias&&(gt=x.ni(gt,this.bias.read(),this.dataFormat)),null!==this.activation&&(gt=this.activation.apply(gt)),gt})}computeOutputShape(t){const e=(t=(0,c.U$)(t)).slice();let s,a,o,u;"channelsFirst"===this.dataFormat?(s=1,a=2,o=3,u=4):(s=4,a=1,o=2,u=3);const p=this.kernelSize[0],g=this.kernelSize[1],b=this.kernelSize[2],E=this.strides[0],k=this.strides[1],O=this.strides[2];return e[s]=this.filters,e[a]=(0,Y.mW)(e[a],E,p,this.padding),e[o]=(0,Y.mW)(e[o],k,g,this.padding),e[u]=(0,Y.mW)(e[u],O,b,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}return i.className="Conv3DTranspose",i})();r.JFn.registerClass(Gt);let Ve=(()=>{class i extends Ct{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new m.Qp("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new m.Qp("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new m.Qp(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=(0,z.Fe)(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=(0,C.Bm)(e.depthwiseRegularizer),this.depthwiseConstraint=(0,N.YZ)(e.depthwiseConstraint),this.pointwiseInitializer=(0,z.Fe)(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=(0,C.Bm)(e.pointwiseRegularizer),this.pointwiseConstraint=(0,N.YZ)(e.pointwiseConstraint)}build(t){if((t=(0,c.U$)(t)).length<this.rank+2)throw new m.Qp(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e]||t[e]<0)throw new m.Qp(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);const s=t[e],a=this.kernelSize.concat([s,this.depthMultiplier]),o=[];for(let p=0;p<this.rank;++p)o.push(1);o.push(s*this.depthMultiplier,this.filters);const u=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",a,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,u,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",o,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,u,this.pointwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,u,this.biasConstraint):null,this.inputSpec=[new f.eO({ndim:this.rank+2,axes:{[e]:s}})],this.built=!0}call(t,e){return(0,r.DZQ)(()=>{let s;if(t=(0,c.un)(t),1===this.rank)throw new m.EH("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=r.mgz(t,[0,2,3,1])),s=r.wdz(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(s=x.ni(s,this.bias.read(),this.dataFormat)),null!=this.activation&&(s=this.activation.apply(s)),"channelsFirst"===this.dataFormat&&(s=r.mgz(s,[0,3,1,2])),s})}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=(0,z.zo)(this.depthwiseInitializer),t.pointwiseInitializer=(0,z.zo)(this.pointwiseInitializer),t.depthwiseRegularizer=(0,C.R9)(this.depthwiseRegularizer),t.pointwiseRegularizer=(0,C.R9)(this.pointwiseRegularizer),t.depthwiseConstraint=(0,N.uH)(this.depthwiseConstraint),t.pointwiseConstraint=(0,N.uH)(this.pointwiseConstraint),t}}return i.className="SeparableConv",i})();r.JFn.registerClass((()=>{class i extends Ve{constructor(t){super(2,t)}}return i.className="SeparableConv2D",i})()),r.JFn.registerClass((()=>{class i extends Ct{constructor(t){super(1,t),i.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!D.HP(t.kernelSize,"number",1,1))throw new m.Qp(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}return i.className="Conv1D",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.cropping="number"==typeof t.cropping?[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"==typeof t.cropping[0]?[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return(0,r.DZQ)(()=>{if(t=(0,c.un)(t),"channelsLast"===this.dataFormat){const s=x.r0(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return x.r0(s,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const s=x.r0(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return x.r0(s,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Cropping2D",i})());let Yt=(()=>{class i extends f.Wd{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,P.uM)(this.dataFormat),this.interpolation=null==t.interpolation?"nearest":t.interpolation,(0,P.uU)(this.interpolation)}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],null==t[2]?null:this.size[0]*t[2],null==t[3]?null:this.size[1]*t[3]]:[t[0],null==t[1]?null:this.size[0]*t[1],null==t[2]?null:this.size[1]*t[2],t[3]]}call(t,e){return r.DZQ(()=>{let s=(0,c.un)(t);const a=s.shape;if("channelsFirst"===this.dataFormat){s=r.mgz(s,[0,2,3,1]);const o=this.size[0]*a[2],u=this.size[1]*a[3],p="nearest"===this.interpolation?r.Slp.resizeNearestNeighbor(s,[o,u]):r.Slp.resizeBilinear(s,[o,u]);return r.mgz(p,[0,3,1,2])}{const o=this.size[0]*a[1],u=this.size[1]*a[2];return"nearest"===this.interpolation?r.Slp.resizeNearestNeighbor(s,[o,u]):r.Slp.resizeBilinear(s,[o,u])}})}getConfig(){const t={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}}return i.className="UpSampling2D",i})();r.JFn.registerClass(Yt);let qt=(()=>{class i extends wt{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=(0,z.Fe)(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=(0,N.YZ)(t.depthwiseConstraint),this.depthwiseRegularizer=(0,C.Bm)(t.depthwiseRegularizer)}build(t){if((t=(0,c.U$)(t)).length<4)throw new m.Qp(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e="channelsFirst"===this.dataFormat?1:3;if(null==t[e]||t[e]<0)throw new m.Qp(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const s=t[e];this.depthwiseKernel=this.addWeight("depthwise_kernel",[this.kernelSize[0],this.kernelSize[1],s,this.depthMultiplier],null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[s*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return(0,r.DZQ)(()=>{let s=function Je(i,n,t=[1,1],e="valid",s,a){return(0,r.DZQ)(()=>{null==s&&(s=(0,rt.VI)()),(0,P.uM)(s);let o=h(i,s);if(4!==i.rank)throw new m.Qp(`Input for depthwiseConv2d is required to be 4-D, but is instead ${i.rank}-D`);if(4!==n.rank)throw new m.Qp(`depthwiseKernel is required to be 4-D, but is instead ${n.rank}-D`);return o=r.Gl3(o,n,t,"same"===e?"same":"valid","NHWC",a),"channelsFirst"===s&&(o=r.mgz(o,[0,3,1,2])),o})}(t=(0,c.un)(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(s=x.ni(s,this.bias.read(),this.dataFormat)),null!=this.activation&&(s=this.activation.apply(s)),s})}computeOutputShape(t){t=(0,c.U$)(t);const s="channelsFirst"===this.dataFormat?t[3]:t[2],a="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,o=(0,Y.Ol)("channelsFirst"===this.dataFormat?t[2]:t[1],this.kernelSize[0],this.padding,this.strides[0]),u=(0,Y.Ol)(s,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],a,o,u]:[t[0],o,u,a]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=(0,z.zo)(this.depthwiseInitializer),t.depthwiseRegularizer=(0,C.R9)(this.depthwiseRegularizer),t.depthwiseConstraint=(0,N.uH)(this.depthwiseRegularizer),t}}return i.className="DepthwiseConv2D",i})();r.JFn.registerClass(qt);var et=l(89119),_t=l(75768),At=l(53340);function te(i,n,t,e){if(Array.isArray(i)){if(null!=n||null!=t)throw new m.Qp("When inputs is an array, neither initialState or constants should be provided");null!=e&&(t=i.slice(i.length-e,i.length),i=i.slice(0,i.length-e)),i.length>1&&(n=i.slice(1,i.length)),i=i[0]}function s(a){return null==a||Array.isArray(a)?a:[a]}return{inputs:i,initialState:n=s(n),constants:t=s(t)}}function ee(i,n,t,e=!1,s,a,o=!1,u=!1){return r.DZQ(()=>{const p=n.shape.length;if(p<3)throw new m.Qp(`Input should be at least 3D, but is ${p}D.`);const g=[1,0].concat(et.y1(2,p));if(n=r.mgz(n,g),null!=a)throw new m.EH("The rnn() functoin of the deeplearn.js backend does not support constants yet.");o&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=s&&((s=r.wgE(r.wgE(s,"bool"),"float32")).rank===p-1&&(s=r.UG6(s,-1)),s=r.mgz(s,g)),e&&(n=r.BEg(n,0),null!=s&&(s=r.BEg(s,0)));const b=[];let E,k=t;const O=n.shape[0],_=r.K$i(n);let tt,V;null!=s&&(tt=r.K$i(s));for(let J=0;J<O;++J){const at=_[J],lt=r.DZQ(()=>i(at,k));if(null==s)E=lt[0],k=lt[1];else{const mt=r.DZQ(()=>{const ht=tt[J],dt=r.jbE(r.P61(ht),ht);return{output:r.WQq(r.lKK(lt[0],ht),r.lKK(k[0],dt)),newStates:k.map((nn,rn)=>r.WQq(r.lKK(lt[1][rn],ht),r.lKK(nn,dt)))}});E=mt.output,k=mt.newStates}u&&b.push(E)}return u&&(V=r.t$z(b,1)),[E,V,k]})}let Dt=(()=>{class i extends f.Wd{constructor(t){let e;if(super(t),null==t.cell)throw new m.Qp("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new $t({cells:t.cell}):t.cell,null==e.stateSize)throw new m.Qp("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new f.eO({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;return et.y1(0,t).map(e=>null)}return this.states_}setStates(t){this.states_=t}computeOutputShape(t){(0,c.TT)(t)&&(t=t[0]);let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const s=e[0];let a;if(a=this.returnSequences?[t[0],t[1],s]:[t[0],s],this.returnState){const o=[];for(const u of e)o.push([t[0],u]);return[a].concat(o)}return a}computeMask(t,e){return r.DZQ(()=>{Array.isArray(e)&&(e=e[0]);const s=this.returnSequences?e:null;if(this.returnState){const a=this.states.map(o=>null);return[s].concat(a)}return s})}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let s=0;s<t;++s)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new m.EH("Constants support is not implemented in RNN yet.");(0,c.TT)(t)&&(t=t[0]);const s=this.stateful?t[0]:null,a=t.slice(2);this.inputSpec[0]=new f.eO({shape:[s,null,...a]});const o=[t[0]].concat(t.slice(2));let u;if(this.cell.build(o),u=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!r.ZSL.arraysEqual(this.stateSpec.map(p=>p.shape[p.shape.length-1]),u))throw new m.Qp(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=u.map(p=>new f.eO({shape:[null,p]}));this.stateful&&this.resetStates()}resetStates(t,e=!1){(0,r.DZQ)(()=>{if(!this.stateful)throw new m.l7("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape[0];if(null==s)throw new m.Qp("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(a=>r.Ul9([s,a])):[r.Ul9([s,this.cell.stateSize])];else if(null==t)r.ASo(this.states_),null!=this.keptStates&&(r.ASo(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(a=>r.Ul9([s,a])):this.states_[0]=r.Ul9([s,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new m.Qp(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);!0===e?this.keptStates.push(this.states_.slice()):r.ASo(this.states_);for(let a=0;a<this.states_.length;++a){const o=t[a],u=Array.isArray(this.cell.stateSize)?this.cell.stateSize[a]:this.cell.stateSize,p=[s,u];if(!r.ZSL.arraysEqual(o.shape,p))throw new m.Qp(`State ${a} is incompatible with layer ${this.name}: expected shape=${p}, received shape=${o.shape}`);this.states_[a]=o}}this.states_=this.states_.map(a=>r.aCs(a.clone()))})}apply(t,e){let s=null==e?null:e.initialState,a=null==e?null:e.constants;null==e&&(e={});const o=te(t,s,a,this.numConstants);t=o.inputs,s=o.initialState,a=o.constants;let u=[],p=[];if(null!=s){e.initialState=s,u=u.concat(s),this.stateSpec=[];for(const b of s)this.stateSpec.push(new f.eO({shape:b.shape}));p=p.concat(this.stateSpec)}if(null!=a&&(e.constants=a,u=u.concat(a),this.numConstants=a.length),u[0]instanceof f.Ar){const b=[t].concat(u),E=this.inputSpec.concat(p),k=this.inputSpec;this.inputSpec=E;const O=super.apply(b,e);return this.inputSpec=k,O}return super.apply(t,e)}call(t,e){return(0,r.DZQ)(()=>{const s=null==e?null:e.mask,a=null==e?null:e.training;let o=null==e?null:e.initialState;t=(0,c.un)(t),null==o&&(o=this.stateful?this.states_:this.getInitialState(t));const u=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(o.length!==u)throw new m.Qp(`RNN Layer has ${u} state(s) but was passed ${o.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const p={training:a},b=ee((tt,V)=>{const J=this.cell.call([tt].concat(V),p);return[J[0],J.slice(1)]},t,o,this.goBackwards,s,null,this.unroll,this.returnSequences),E=b[0],k=b[1],O=b[2];this.stateful&&this.resetStates(O,a);const _=this.returnSequences?k:E;return this.returnState?[_].concat(O):_})}getInitialState(t){return(0,r.DZQ)(()=>{let e=r.Ul9(t.shape);return e=r.czq(e,[1,2]),e=x.UG(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(s=>s>1?x.Vs(e,[1,s]):e):this.cell.stateSize>1?[x.Vs(e,[1,this.cell.stateSize])]:[e]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const s=this.cell.getConfig();return this.getClassName()===i.className&&(e.cell={className:this.cell.getClassName(),config:s}),Object.assign(Object.assign(Object.assign({},s),t),e)}static fromConfig(t,e,s={}){const o=(0,At.i)(e.cell,s);return new t(Object.assign(e,{cell:o}))}}return i.className="RNN",i})();r.JFn.registerClass(Dt);class xt extends f.Wd{}let Qt=(()=>{class i extends xt{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,(0,D.oo)(this.units,"units"),this.activation=(0,K.b_)(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,z.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,z.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,z.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=(0,C.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,C.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,C.Bm)(t.biasRegularizer),this.kernelConstraint=(0,N.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,N.YZ)(t.recurrentConstraint),this.biasConstraint=(0,N.YZ)(t.biasConstraint),this.dropout=et.jk([1,et.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=et.jk([1,et.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=(0,c.U$)(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return(0,r.DZQ)(()=>{if(2!==t.length)throw new m.Qp(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let s=t[1];t=t[0];const a=null!=e.training&&e.training;let o;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vt({ones:()=>r.P61(t),rate:this.dropout,training:a,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vt({ones:()=>r.P61(s),rate:this.recurrentDropout,training:a,dropoutFunc:this.dropoutFunc}));const u=this.dropoutMask,p=this.recurrentDropoutMask;o=x.Om(null!=u?r.lKK(t,u):t,this.kernel.read()),null!=this.bias&&(o=x.ni(o,this.bias.read())),null!=p&&(s=r.lKK(s,p));let g=r.WQq(o,x.Om(s,this.recurrentKernel.read()));return null!=this.activation&&(g=this.activation.apply(g)),[g,g]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,K.Bu)(this.activation),useBias:this.useBias,kernelInitializer:(0,z.zo)(this.kernelInitializer),recurrentInitializer:(0,z.zo)(this.recurrentInitializer),biasInitializer:(0,z.zo)(this.biasInitializer),kernelRegularizer:(0,C.R9)(this.kernelRegularizer),recurrentRegularizer:(0,C.R9)(this.recurrentRegularizer),biasRegularizer:(0,C.R9)(this.biasRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),kernelConstraint:(0,N.uH)(this.kernelConstraint),recurrentConstraint:(0,N.uH)(this.recurrentConstraint),biasConstraint:(0,N.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign(Object.assign({},t),e)}}return i.className="SimpleRNNCell",i})();r.JFn.registerClass(Qt);let se=(()=>{class i extends Dt{constructor(t){t.cell=new Qt(t),super(t)}call(t,e){return(0,r.DZQ)(()=>(null!=this.cell.dropoutMask&&(r.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(r.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})))}static fromConfig(t,e){return new t(e)}}return i.className="SimpleRNN",i})();r.JFn.registerClass(se);let Ut=(()=>{class i extends xt{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new m.Qp("GRUCell does not support reset_after parameter set to true.");this.units=t.units,(0,D.oo)(this.units,"units"),this.activation=(0,K.b_)(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=(0,K.b_)(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,z.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,z.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,z.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=(0,C.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,C.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,C.Bm)(t.biasRegularizer),this.kernelConstraint=(0,N.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,N.YZ)(t.recurrentConstraint),this.biasConstraint=(0,N.YZ)(t.biasConstraint),this.dropout=et.jk([1,et.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=et.jk([1,et.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=(0,c.U$)(t),this.kernel=this.addWeight("kernel",[t[t.length-1],3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(t,e){return(0,r.DZQ)(()=>{if(2!==t.length)throw new m.Qp(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const s=null!=e.training&&e.training;let a=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vt({ones:()=>r.P61(t),rate:this.dropout,training:s,count:3,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vt({ones:()=>r.P61(a),rate:this.recurrentDropout,training:s,count:3,dropoutFunc:this.dropoutFunc}));const u=this.recurrentDropoutMask;let p,g,b;0<this.dropout&&this.dropout<1&&(t=r.lKK(t,this.dropoutMask[0]));let E=x.Om(t,this.kernel.read());this.useBias&&(E=x.ni(E,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(a=r.lKK(a,u[0]));const k=this.recurrentKernel.read(),[O,_]=r.lDo(k,[2*this.units,this.units],k.rank-1),tt=x.Om(a,O),[V,J,at]=r.lDo(E,3,E.rank-1),[lt,mt]=r.lDo(tt,2,tt.rank-1);p=this.recurrentActivation.apply(r.WQq(V,lt)),g=this.recurrentActivation.apply(r.WQq(J,mt));const ht=x.Om(r.lKK(g,a),_);b=this.activation.apply(r.WQq(at,ht));const dt=r.WQq(r.lKK(p,a),r.lKK(r.WQq(1,r.HZy(p)),b));return[dt,dt]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,K.Bu)(this.activation),recurrentActivation:(0,K.Bu)(this.recurrentActivation),useBias:this.useBias,kernelInitializer:(0,z.zo)(this.kernelInitializer),recurrentInitializer:(0,z.zo)(this.recurrentInitializer),biasInitializer:(0,z.zo)(this.biasInitializer),kernelRegularizer:(0,C.R9)(this.kernelRegularizer),recurrentRegularizer:(0,C.R9)(this.recurrentRegularizer),biasRegularizer:(0,C.R9)(this.biasRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),kernelConstraint:(0,N.uH)(this.kernelConstraint),recurrentConstraint:(0,N.uH)(this.recurrentConstraint),biasConstraint:(0,N.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign(Object.assign({},t),e)}}return i.className="GRUCell",i})();r.JFn.registerClass(Ut);let ne=(()=>{class i extends Dt{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Ut(t),super(t)}call(t,e){return(0,r.DZQ)(()=>(null!=this.cell.dropoutMask&&(r.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(r.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}return i.className="GRU",i})();r.JFn.registerClass(ne);let Et=(()=>{class i extends xt{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,(0,D.oo)(this.units,"units"),this.activation=(0,K.b_)(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=(0,K.b_)(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,z.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,z.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,z.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=(0,C.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,C.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,C.Bm)(t.biasRegularizer),this.kernelConstraint=(0,N.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,N.YZ)(t.recurrentConstraint),this.biasConstraint=(0,N.YZ)(t.biasConstraint),this.dropout=et.jk([1,et.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=et.jk([1,et.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.dropoutFunc=t.dropoutFunc,this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;let a;if(t=(0,c.U$)(t),this.kernel=this.addWeight("kernel",[t[t.length-1],4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const o=this.biasInitializer,u=this.units;a=new((e=class extends z.H4{apply(g,b){const E=o.apply([u]),k=(new z.sN).apply([u]),O=o.apply([2*u]);return x.ly(x.ly(E,k),O)}}).className="CustomInit",e)}else a=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,a,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return(0,r.DZQ)(()=>{const s=null!=e.training&&e.training;if(3!==t.length)throw new m.Qp(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let a=t[1];const o=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vt({ones:()=>r.P61(t),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vt({ones:()=>r.P61(a),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const p=this.recurrentDropoutMask;let g,b,E,k;0<this.dropout&&this.dropout<1&&(t=r.lKK(t,this.dropoutMask[0]));let O=x.Om(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(a=r.lKK(a,p[0])),O=r.WQq(O,x.Om(a,this.recurrentKernel.read())),this.useBias&&(O=x.ni(O,this.bias.read()));const[_,tt,V,J]=r.lDo(O,4,O.rank-1);g=this.recurrentActivation.apply(_),b=this.recurrentActivation.apply(tt),E=r.WQq(r.lKK(b,o),r.lKK(g,this.activation.apply(V))),k=this.recurrentActivation.apply(J);const at=r.lKK(k,this.activation.apply(E));return[at,at,E]})}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,K.Bu)(this.activation),recurrentActivation:(0,K.Bu)(this.recurrentActivation),useBias:this.useBias,kernelInitializer:(0,z.zo)(this.kernelInitializer),recurrentInitializer:(0,z.zo)(this.recurrentInitializer),biasInitializer:(0,z.zo)(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:(0,C.R9)(this.kernelRegularizer),recurrentRegularizer:(0,C.R9)(this.recurrentRegularizer),biasRegularizer:(0,C.R9)(this.biasRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),kernelConstraint:(0,N.uH)(this.kernelConstraint),recurrentConstraint:(0,N.uH)(this.recurrentConstraint),biasConstraint:(0,N.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign(Object.assign({},t),e)}}return i.className="LSTMCell",i})();r.JFn.registerClass(Et);let ie=(()=>{class i extends Dt{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Et(t),super(t)}call(t,e){return(0,r.DZQ)(()=>(null!=this.cell.dropoutMask&&(r.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(r.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}return i.className="LSTM",i})();r.JFn.registerClass(ie);let $t=(()=>{class i extends xt{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return(0,r.DZQ)(()=>{let s=t.slice(1);const a=[];for(const p of this.cells.slice().reverse())Array.isArray(p.stateSize)?a.push(s.splice(0,p.stateSize.length)):a.push(s.splice(0,1));a.reverse();const o=[];let u;for(let p=0;p<this.cells.length;++p){const g=this.cells[p];s=a[p],u=0===p?[t[0]].concat(s):[u[0]].concat(s),u=g.call(u,e),o.push(u.slice(1))}s=[];for(const p of o.slice().reverse())s.push(...p);return[u[0]].concat(s)})}build(t){let e;(0,c.TT)(t)&&(t=t[0]),this.cells.forEach((s,a)=>{(0,P.IU)(`RNNCell_${a}`,()=>{s.build(t),e=Array.isArray(s.stateSize)?s.stateSize[0]:s.stateSize,t=[t[0],e]})}),this.built=!0}getConfig(){const t=super.getConfig(),a={cells:this.cells.map(o=>({className:o.getClassName(),config:o.getConfig()}))};return Object.assign(Object.assign({},t),a)}static fromConfig(t,e,s={}){const a=[];for(const o of e.cells)a.push((0,At.i)(o,s));return new t({cells:a})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const s of this.cells)e.push(...s.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return(0,_t.ex)(t)}setWeights(t){const e=[];for(const s of this.cells){const o=t.splice(s.weights.length);for(let u=0;u<s.weights.length;++u)e.push([s.weights[u],o[u]])}(0,_t.UM)(e)}}return i.className="StackedRNNCells",i})();function vt(i){const{ones:n,rate:t,training:e=!1,count:s=1,dropoutFunc:a}=i,o=()=>null!=a?a(n(),t):x.EZ(n(),t),u=()=>x.Ls(o,n,e);return!s||s<=1?r.aCs(u().clone()):Array(s).fill(void 0).map(u).map(g=>r.aCs(g.clone()))}r.JFn.registerClass($t);let Ye=(()=>{class i extends Dt{constructor(t){if(t.unroll)throw new m.EH("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new m.EH("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new f.eO({ndim:5})]}call(t,e){return r.DZQ(()=>{if(null!=this.cell.dropoutMask&&(r.ASo(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(r.ASo(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new m.Qp("ConvRNN2D cell does not support constants");return super.call(t,{mask:null==e?null:e.mask,training:null==e?null:e.training,initialState:null==e?null:e.initialState})})}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return r.DZQ(()=>{const{stateSize:e}=this.cell,a=this.computeSingleOutputShape(t.shape),o=[a[0],...a.slice(2)],u=r.Ul9(o);return Array.isArray(e)?Array(e.length).fill(u):[u]})}resetStates(t,e=!1){r.DZQ(()=>{if(!this.stateful)throw new m.l7("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape,a=this.computeSingleOutputShape(s),o=[a[0],...a.slice(2)];if(null==s[0])throw new m.Qp("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(()=>r.Ul9(o)):[r.Ul9(o)];else if(null==t)r.ASo(this.states_),null!=this.keptStates&&(r.ASo(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>r.Ul9(o)):this.states_[0]=r.Ul9(o);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new m.Qp(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):r.ASo(this.states_);for(let p=0;p<this.states_.length;++p){const g=t[p],b=o;if(!r.ZSL.arraysEqual(g.shape,b))throw new m.Qp(`State ${p} is incompatible with layer ${this.name}: expected shape=${b}, received shape=${g.shape}`);this.states_[p]=g}}this.states_=this.states_.map(p=>r.aCs(p.clone()))})}computeSingleOutputShape(t){const{dataFormat:e,filters:s,kernelSize:a,padding:o,strides:u,dilationRate:p}=this.cell,g="channelsFirst"===e,E=t[g?4:3],k=(0,Y.Ol)(t[g?3:2],a[0],o,u[0],p[0]),O=(0,Y.Ol)(E,a[1],o,u[1],p[1]);return[...t.slice(0,2),...g?[s,k,O]:[k,O,s]]}}return i.className="ConvRNN2D",i})(),Zt=(()=>{class i extends Et{constructor(t){const{filters:e,kernelSize:s,strides:a,padding:o,dataFormat:u,dilationRate:p}=t;super(Object.assign(Object.assign({},t),{units:e})),this.filters=e,(0,D.oo)(this.filters,"filters"),this.kernelSize=(0,Y.J)(s,2,"kernelSize"),this.kernelSize.forEach(g=>(0,D.oo)(g,"kernelSize")),this.strides=(0,Y.J)(a||1,2,"strides"),this.strides.forEach(g=>(0,D.oo)(g,"strides")),this.padding=o||"valid",(0,P.tB)(this.padding),this.dataFormat=u||"channelsLast",(0,P.uM)(this.dataFormat),this.dilationRate=(0,Y.J)(p||1,2,"dilationRate"),this.dilationRate.forEach(g=>(0,D.oo)(g,"dilationRate"))}build(t){var e;t=(0,c.U$)(t);const s="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[s])throw new m.Qp(`The channel dimension of the input should be defined. Found ${t[s]}`);const u=this.kernelSize.concat([t[s],4*this.filters]);this.kernel=this.addWeight("kernel",u,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const p=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",p,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let g;if(this.unitForgetBias){const b=this.biasInitializer,E=this.filters;g=new((e=class extends z.H4{apply(O,_){const tt=b.apply([E]),V=r.SaS([E]),J=b.apply([2*E]);return x.u1([tt,V,J])}}).className="CustomInit",e)}else g=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,g,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return r.DZQ(()=>{if(3!==t.length)throw new m.Qp(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const s=e.training||!1,a=t[0],o=t[1],u=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=vt({ones:()=>r.P61(a),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const g=this.dropoutMask,b=(Dn,an,Sn)=>an&&an[Sn]?r.lKK(an[Sn],Dn):Dn;let E=b(a,g,0),k=b(a,g,1),O=b(a,g,2),_=b(a,g,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=vt({ones:()=>r.P61(o),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const tt=this.recurrentDropoutMask;let V=b(o,tt,0),J=b(o,tt,1),at=b(o,tt,2),lt=b(o,tt,3);const[ht,dt,gt,gs]=r.lDo(this.kernel.read(),4,3),[nn,rn,Jn,Xn]=this.useBias?r.lDo(this.bias.read(),4):[null,null,null,null];E=this.inputConv(E,ht,nn,this.padding),k=this.inputConv(k,dt,rn,this.padding),O=this.inputConv(O,gt,Jn,this.padding),_=this.inputConv(_,gs,Xn,this.padding);const[Yn,qn,_n,ti]=r.lDo(this.recurrentKernel.read(),4,3);V=this.recurrentConv(V,Yn),J=this.recurrentConv(J,qn),at=this.recurrentConv(at,_n),lt=this.recurrentConv(lt,ti);const ei=this.recurrentActivation.apply(r.WQq(E,V)),si=this.recurrentActivation.apply(r.WQq(k,J)),Cn=r.WQq(r.lKK(si,u),r.lKK(ei,this.activation.apply(r.WQq(O,at)))),An=r.lKK(this.recurrentActivation.apply(r.WQq(_,lt)),this.activation.apply(Cn));return[An,An,Cn]})}getConfig(){const s=function(i,n){var t={};for(var e in i)Object.prototype.hasOwnProperty.call(i,e)&&n.indexOf(e)<0&&(t[e]=i[e]);if(null!=i&&"function"==typeof Object.getOwnPropertySymbols){var s=0;for(e=Object.getOwnPropertySymbols(i);s<e.length;s++)n.indexOf(e[s])<0&&Object.prototype.propertyIsEnumerable.call(i,e[s])&&(t[e[s]]=i[e[s]])}return t}(super.getConfig(),["units"]),a={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},s),a)}inputConv(t,e,s,a){const o=r.Xtf(t,e,this.strides,a||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return s?x.ni(o,s,this.dataFormat):o}recurrentConv(t,e){return r.Xtf(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}return i.className="ConvLSTM2DCell",i})();r.JFn.registerClass(Zt),r.JFn.registerClass((()=>{class i extends Ye{constructor(t){const e=new Zt(t);super(Object.assign(Object.assign({},t),{cell:e}))}static fromConfig(t,e){return new t(e)}}return i.className="ConvLSTM2D",i})());let jt=(()=>{class i extends f.Wd{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const e=t.shape,s=[];for(let a=0;a<this.noiseShape.length;++a)s.push(null==this.noiseShape[a]?e[a]:this.noiseShape[a]);return s}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t);if(0<this.rate&&this.rate<1){const a=null!=e.training&&e.training,o=this.getNoiseShape(s);return x.Ls(()=>x.EZ(s,this.rate,o,this.seed),()=>s,a)}return t})}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}return i.className="Dropout",i})();r.JFn.registerClass(jt),r.JFn.registerClass((()=>{class i extends jt{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}return i.className="SpatialDropout1D",i})());let oe=(()=>{class i extends f.Wd{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,(0,D.oo)(this.units,"units"),this.activation=(0,K.b_)(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=(0,z.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=(0,z.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=(0,N.YZ)(t.kernelConstraint),this.biasConstraint=(0,N.YZ)(t.biasConstraint),this.kernelRegularizer=(0,C.Bm)(t.kernelRegularizer),this.biasRegularizer=(0,C.Bm)(t.biasRegularizer),this.activityRegularizer=(0,C.Bm)(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const e=(t=(0,c.U$)(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){const e=(t=(0,c.U$)(t)).slice();return e[e.length-1]=this.units,e}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t),a=(0,D.Cd)(this.activation.getClassName());let o;return null!=a?o=x.Om(s,this.kernel.read(),a,this.bias?this.bias.read():null):(o=x.Om(s,this.kernel.read()),null!=this.bias&&(o=x.ni(o,this.bias.read())),null!=this.activation&&(o=this.activation.apply(o))),o})}getConfig(){const t={units:this.units,activation:(0,K.Bu)(this.activation),useBias:this.useBias,kernelInitializer:(0,z.zo)(this.kernelInitializer),biasInitializer:(0,z.zo)(this.biasInitializer),kernelRegularizer:(0,C.R9)(this.kernelRegularizer),biasRegularizer:(0,C.R9)(this.biasRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),kernelConstraint:(0,N.uH)(this.kernelConstraint),biasConstraint:(0,N.uH)(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Dense",i})();r.JFn.registerClass(oe);let le=(()=>{class i extends f.Wd{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=(0,c.U$)(t);for(const e of t.slice(1))if(null==e)throw new m.Qp(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],(0,et.no)(t,1)]}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);let s=(0,c.un)(t);if("channelsFirst"===this.dataFormat&&s.rank>1){const a=[0];for(let o=2;o<s.rank;++o)a.push(o);a.push(1),s=(0,r.mgz)(s,a)}return x.PS(s)})}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}return i.className="Flatten",i})();r.JFn.registerClass(le),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.supportsMasking=!0,this.activation=(0,K.b_)(t.activation)}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t);return this.activation.apply(s)})}getConfig(){const t={activation:(0,K.Bu)(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Activation",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return(0,r.DZQ)(()=>(t=(0,c.un)(t),x.ux(t,this.n)))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}return i.className="RepeatVector",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.targetShape=t.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,e){const s="Total size of new array must be unchanged.",a=e.slice();let o=1,u=null;for(let g=0;g<a.length;++g){const b=a[g];if(this.isUnknown(b)){if(null!==u)throw new m.Qp("Can only specifiy one unknown dimension.");u=g}else o*=b}const p=(0,et.no)(t);if(null!==u){if(0===o||p%o!=0)throw new m.Qp(s);a[u]=p/o}else if(p!==o)throw new m.Qp(s);return a}computeOutputShape(t){let e=!1;for(let s=0;s<t.length;++s)if(this.isUnknown(t[s])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t),a=s.shape,o=a.slice(0,1).concat(this.fixUnknownDimension(a.slice(1),this.targetShape));return(0,r.tQQ)(s,o)})}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Reshape",i})());let de=(()=>{class i extends f.Wd{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const e=(0,et.y1)(1,t.dims.length+1);if(!r.ZSL.arraysEqual(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new f.eO({ndim:this.dims.length+1})]}computeOutputShape(t){const e=(t=(0,c.U$)(t)).slice();return this.dims.forEach((s,a)=>{e[a+1]=t[s]}),e}call(t,e){return(0,r.mgz)((0,c.un)(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Permute",i})();r.JFn.registerClass(de),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const s=(0,c.un)(t);return(0,r.bzn)((0,r.Ec)(s,this.maskValue),-1)}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t),u=(0,r.bzn)((0,r.Ec)(s,this.maskValue),-1,!0);return(0,r.lKK)(s,(0,r.wgE)(u,s.dtype))})}}return i.className="Masking",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=null==t.inputLength?[e,null]:[e].concat(D.st(t.inputLength))}this.inputDim=t.inputDim,D.oo(this.inputDim,"inputDim"),this.outputDim=t.outputDim,D.oo(this.outputDim,"outputDim"),this.embeddingsInitializer=(0,z.Fe)(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=(0,C.Bm)(t.embeddingsRegularizer),this.activityRegularizer=(0,C.Bm)(t.activityRegularizer),this.embeddingsConstraint=(0,N.YZ)(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return(0,r.DZQ)(()=>this.maskZero?(t=(0,c.un)(t),(0,r.Ec)(t,(0,r.POl)(t))):null)}computeOutputShape(t){if(t=(0,c.U$)(t),null==this.inputLength)return[...t,this.outputDim];const e=D.st(this.inputLength);if(e.length!==t.length-1)throw new m.Qp(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let s=0;for(let a=0;a<e.length;++a){const o=e[a],u=t[a+1];if(null!=o&&null!=u&&o!==u)throw new m.Qp(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);null==o&&(e[s]=u),s++}}return[t[0],...e,this.outputDim]}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);let s=(0,c.un)(t);"int32"!==s.dtype&&(s=x.wg(s,"int32"));const a=x.kg(this.embeddings.read(),(0,r.tQQ)(s,[s.size]));return(0,r.tQQ)(a,(0,c.U$)(this.computeOutputShape(s.shape)))})}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:(0,z.zo)(this.embeddingsInitializer),embeddingsRegularizer:(0,C.R9)(this.embeddingsRegularizer),activityRegularizer:(0,C.R9)(this.activityRegularizer),embeddingsConstraint:(0,N.uH)(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Embedding",i})());var me=l(55294);class zt extends f.Wd{constructor(n){super(n||{}),this.supportsMasking=!0}mergeFunction(n){throw new m.EH}computeElementwiseOpOutputShape(n,t){if(null==n||null==t)return null;if(n.length<t.length)return this.computeElementwiseOpOutputShape(t,n);if(0===t.length)return n;const e=n.slice(0,n.length-t.length);for(let s=0;s<t.length;++s){const a=n[n.length-t.length+s],o=t[s];if(null==a||null==o||a<0||o<0)e.push(null);else if(1===a)e.push(o);else if(1===o)e.push(a);else{if(a!==o)throw new m.Qp("Operands could not be broadcast together with shapes "+JSON.stringify(n)+" "+JSON.stringify(t));e.push(a)}}return e}build(n){if(Array.isArray(n)&&!Array.isArray(n[0])&&(n=[(0,c.U$)(n)]),n.length<2)throw new m.Qp(`A merge layer should be called on an Array of at least 2 inputs. Got ${n.length} input(s).`);let t=[];for(const a of n)null!=a&&null!==a[0]&&t.push(a[0]);if(t=D.Am(t),t.length>1)throw new m.Qp(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(n)}.`);let e=null==n[0]?null:n[0].slice(1);for(let a=1;a<n.length;++a){const o=null==n[a]?null:n[a].slice(1);e=this.computeElementwiseOpOutputShape(e,o)}const s=n.map(a=>a.length);this.reshapeRequired=-1!==n.indexOf(null)||1!==D.Am(s).length}call(n,t){return(0,r.DZQ)(()=>{if(this.reshapeRequired){const e=[],s=n.map(a=>a.rank);if(-1===s.indexOf(null)){const a=et.T9(s);for(let o of n){const u=o.rank;for(let p=0;p<a-u;++p)o=x.UG(o,1);e.push(o)}return this.mergeFunction(e)}{let a=!1;for(const p of n){const g=p.rank;if(null==g){const b=p.shape,E=b[0],k=b.slice(1).concat([E]);let O=r.tQQ(p,[E].concat(et.no(b.slice(1))));O=r.mgz(O,[1,0]),O=r.tQQ(O,k),e.push(O),a=!0}else if(g>1){const b=et.y1(1,g).concat([0]);e.push(r.mgz(p,b)),a=!0}else e.push(p)}let o=this.mergeFunction(e);const u=o.rank;if(a)if(null==u){const p=o.shape,b=p[p.length-1],E=[b].concat(p.slice(0,p.length-1));o=r.tQQ(r.mgz(r.tQQ(o,[-1,b]),[1,0]),E)}else if(u>1){const p=[u-1].concat(et.y1(0,u-1));o=r.mgz(o,p)}return o}}return this.mergeFunction(n)})}computeOutputShape(n){let t;t=null==n[0]?null:n[0].slice(1);for(let s=1;s<n.length;++s){const a=null==n[s]?null:n[s].slice(1);t=this.computeElementwiseOpOutputShape(t,a)}let e=[];for(const s of n)null!=s&&null!==s[0]&&e.push(s[0]);return e=D.Am(e),t=1===e.length?e.concat(t):[null].concat(t),t}computeMask(n,t){return r.DZQ(()=>{if(null==t)return null;if(!Array.isArray(t))throw new m.Qp("`mask` should be an Array");if(!Array.isArray(n))throw new m.Qp("`inputs` should be an Array");if(t.length!==n.length)throw new m.Qp(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${n.length} vs ${t.length})`);if(t.every(s=>null==s))return null;let e=(t=t.map(s=>null==s?s:r.UG6(s,0)))[0];for(let s=1;s<t.length-1;++s)e=r.n76(e,t[s]);return e})}}let Nt=(()=>{class i extends zt{constructor(t){super(t)}mergeFunction(t){return(0,r.DZQ)(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=r.WQq(e,t[s]);return e})}}return i.className="Add",i})();r.JFn.registerClass(Nt);let Tt=(()=>{class i extends zt{constructor(t){super(t)}mergeFunction(t){return(0,r.DZQ)(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=r.lKK(e,t[s]);return e})}}return i.className="Multiply",i})();r.JFn.registerClass(Tt);let Kt=(()=>{class i extends zt{constructor(t){super(t)}mergeFunction(t){return(0,r.DZQ)(()=>{let e=t[0].clone();for(let s=1;s<t.length;++s)e=r.WQq(e,t[s]);return r.lKK(1/t.length,e)})}}return i.className="Average",i})();r.JFn.registerClass(Kt);let Ft=(()=>{class i extends zt{constructor(t){super(t)}mergeFunction(t){return(0,r.DZQ)(()=>{let e=t[0];for(let s=1;s<t.length;++s)e=r.PhQ(e,t[s]);return e})}}return i.className="Maximum",i})();r.JFn.registerClass(Ft);let Mt=(()=>{class i extends zt{constructor(t){super(t)}mergeFunction(t){return(0,r.DZQ)(()=>{let e=t[0];for(let s=1;s<t.length;++s)e=r.BpO(e,t[s]);return e})}}return i.className="Minimum",i})();r.JFn.registerClass(Mt);let Lt=(()=>{class i extends zt{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new m.Qp("A `Concatenate` layer should be called on a list of at least 2 inputs");let e=!0;for(const a of t)if(null!=a){e=!1;break}if(e)return;const s=[];for(let a=0;a<t.length;++a){const o=t[a].slice();o.splice(this.axis,1);let u=!1;for(const p of s)if(r.ZSL.arraysEqual(p,o)){u=!0;break}u||s.push(o)}if(s.length>1)throw new m.Qp("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return(0,r.DZQ)(()=>x.u1(t,this.axis))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new m.Qp("A `Concatenate` layer should be called on a list of inputs.");const e=t,s=e[0].slice(),a=this.axis<0?s.length+this.axis:this.axis;for(const o of e.slice(1)){if(null==s[a]||null==o[a]){s[a]=null;break}s[a]+=o[a]}return s}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new m.Qp("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new m.Qp("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new m.Qp(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return r.DZQ(()=>{let s=!0;if(e.forEach(u=>{null==u||(s=!1)}),s)return null;const a=[];for(let u=0;u<t.length;++u)a.push(null==e[u]?r.wgE(r.P61(t[u]),"bool"):e[u].rank<t[u].rank?r.UG6(e[u],-1):e[u]);const o=r.xWs(a,this.axis);return r.Q7R(o,-1,!1)})}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Concatenate",i})();function St(i,n){for(;i<0;)i+=n;return i}r.JFn.registerClass(Lt);let ge=(()=>{class i extends zt{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){r.ZSL.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0],s=t[1];if(e.length>3||s.length>3)throw new m.EH("Dot layer does not support tensors of 4D or higher rank yet.");const a=this.interpretAxes(e,s);if(e[a[0]]!==s[a[1]])throw new m.Qp(`Dimension incompatibility: ${e[a[0]]} !== ${s[a[1]]}`)}mergeFunction(t){if(2!==t.length)throw new m.Qp(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let a,e=t[0],s=t[1];return a=Array.isArray(this.axes)?this.axes.map((o,u)=>St(o,t[u].shape.length)):[St(this.axes,e.shape.length),St(this.axes,s.shape.length)],this.normalize&&(e=(0,me.Yq)(e,a[0]),s=(0,me.Yq)(s,a[1])),function qe(i,n,t){if(i.shape.length>3||n.shape.length>3)throw new m.EH("batchDot is not implemented for tensors of 4D or higher rank yet");if(r.ZSL.assert(i.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${i.shape.length}`),r.ZSL.assert(i.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${n.shape.length}`),"number"==typeof t&&(t=[t,t]),"complex64"===i.dtype||"complex64"===n.dtype)throw new m.EH("batchDot is not implemented for complex64-type Tensors yet.");const e=i.shape.length,s=n.shape.length;null==t&&(t=[e-1,s-2]);const a=t;return r.DZQ(()=>{let o,u;if(e>s){o=e-s;const p=[];for(let g=0;g<o;++g)p.push(1);n=r.tQQ(n,n.shape.concat(p))}else if(s>e){o=s-e;const p=[];for(let g=0;g<o;++g)p.push(1);i=r.tQQ(i,i.shape.concat(p))}else o=0;if(u=2===i.shape.length&&2===n.shape.length?a[0]===a[1]?r.czq(r.lKK(i,n),a[0]):r.czq(r.lKK(r.mgz(i,[1,0]),n),a[1]):r.NoW(i,n,a[0]!==i.shape.length-1,a[1]===n.shape.length-1),o>0){let p;p=e>s?e+s-3:e-1;const g=[];for(let b=p;b<p+o;++b)g.push(b);u=r.r2V(u,g)}return 1===u.shape.length&&(u=r.UG6(u,1)),u})}(e,s,a)}interpretAxes(t,e){let s;return s=Array.isArray(this.axes)?this.axes:[St(this.axes,t.length),St(this.axes,e.length)],s}computeOutputShape(t){r.ZSL.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const e=t[0].slice(),s=t[1].slice();if(e.length>3||s.length>3)throw new m.EH("Dot layer does not support tensors of 4D or higher rank yet.");const a=this.interpretAxes(e,s);e.splice(a[0],1),s.splice(a[1],1),s.splice(0,1);const o=e.concat(s);return 1===o.length&&o.push(1),o}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}return i.className="Dot",i})();function It(i,n,t,e,s,a=.001){let o;if(2===i.rank)o=r.BFc(i,n,t,e,s,a);else if(3===i.rank)o=r.kSi(i,n,t,e,s,a);else{if(4!==i.rank)throw new m.EH(`batchNormalization is not implemented for array of rank ${i.rank} yet`);o=r.T5N(i,n,t,e,s,a)}return o}r.JFn.registerClass(ge),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t);return x.Ls(()=>(0,r.WQq)(x.FE(s.shape,0,this.stddev),s),()=>s,e.training||!1)})}}return i.className="GaussianNoise",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,r.DZQ)(()=>{this.invokeCallHook(t,e);const s=(0,c.un)(t);if(this.rate>0&&this.rate<1){const a=()=>{const o=Math.sqrt(this.rate/(1-this.rate));return(0,r.lKK)(s,x.FE(s.shape,1,o))};return x.Ls(a,()=>s,e.training||!1)}return s})}}return i.className="GaussianDropout",i})()),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||(0,c.un)(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,r.DZQ)(()=>{if(this.rate<1&&this.rate>0){const s=this._getNoiseShape(t),a=()=>{const o=(0,c.un)(t),g=-1.7580993408473766;let b=(0,r.DQN)((0,r.YeY)(s),this.rate);b=x.wg(b,"float32");const E=((1-this.rate)*(1+this.rate*g**2))**-.5,k=-E*g*this.rate,O=(0,r.WQq)((0,r.lKK)(o,b),(0,r.lKK)((0,r.WQq)(b,-1),g));return(0,r.WQq)((0,r.lKK)(O,E),k)};return x.Ls(a,()=>(0,c.un)(t),e.training||!1)}return t})}}return i.className="AlphaDropout",i})());let we=(()=>{class i extends f.Wd{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=(0,z.Fe)(t.betaInitializer||"zeros"),this.gammaInitializer=(0,z.Fe)(t.gammaInitializer||"ones"),this.movingMeanInitializer=(0,z.Fe)(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=(0,z.Fe)(t.movingVarianceInitializer||"ones"),this.betaConstraint=(0,N.YZ)(t.betaConstraint),this.gammaConstraint=(0,N.YZ)(t.gammaConstraint),this.betaRegularizer=(0,C.Bm)(t.betaRegularizer),this.gammaRegularizer=(0,C.Bm)(t.gammaRegularizer)}build(t){t=(0,c.U$)(t);const e=this.axis>=0?this.axis:this.axis+t.length,s=t[e];if(null==s)throw new m.Qp(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new f.eO({ndim:t.length,axes:{[e]:s}})];const a=[s];this.scale&&(this.gamma=this.addWeight("gamma",a,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",a,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",a,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",a,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return(0,r.DZQ)(()=>{const s=null!=e.training&&e.training,a=(0,c.un)(t),o=a.shape,u=o.length,p=et.y1(0,u),g=this.axis>=0?this.axis:this.axis+u;p.splice(g,1);const b=D.fD(1,u);b[g]=o[g];const E=p.slice();E.sort();const k=!r.ZSL.arraysEqual(E,et.y1(0,u).slice(0,u-1));if(!s)return(()=>{if(k){const lt=(0,r.tQQ)(this.movingMean.read(),b),mt=(0,r.tQQ)(this.movingVariance.read(),b),ht=this.center?(0,r.tQQ)(this.beta.read(),b):null,dt=this.scale?(0,r.tQQ)(this.gamma.read(),b):null;return It(a,lt,mt,ht,dt,this.epsilon)}return It(a,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[_,tt,V]=function es(i,n,t,e,s=.001){return r.ZSL.arraysEqual(e.slice().sort(),et.y1(0,i.rank-1))?function _e(i,n,t,e,s=.001){return(0,r.DZQ)(()=>{const a=r.Clk(i,e),o=a.mean,u=a.variance;return[It(i,o,u,t,n,s),o,u]})}(i,n,t,e,s):function ts(i,n,t,e,s=.001){return(0,r.DZQ)(()=>{const a=r.Clk(i,e),o=a.mean,u=a.variance,p=[];for(const _ of et.y1(0,i.rank))-1!==e.indexOf(_)?p.push(1):p.push(i.shape[_]);const g=(0,r.tQQ)(o,p),b=(0,r.tQQ)(u,p),E=null==n?null:(0,r.tQQ)(n,p),k=null==t?null:(0,r.tQQ)(t,p);return[It(i,g,b,k,E,s),o,u]})}(i,n,t,e,s)}(a,this.gamma.read(),this.beta.read(),p,this.epsilon),J=(lt,mt,ht)=>{r.DZQ(()=>{const dt=1-ht,gt=lt.read(),gs=r.lKK(r.jbE(gt,mt),dt);lt.write(r.jbE(gt,gs))})};return(()=>{J(this.movingMean,tt,this.momentum),J(this.movingVariance,V,this.momentum)})(),_})}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:(0,z.zo)(this.betaInitializer),gammaInitializer:(0,z.zo)(this.gammaInitializer),movingMeanInitializer:(0,z.zo)(this.movingMeanInitializer),movingVarianceInitializer:(0,z.zo)(this.movingVarianceInitializer),betaRegularizer:(0,C.R9)(this.betaRegularizer),gammaRegularizer:(0,C.R9)(this.gammaRegularizer),betaConstraint:(0,N.uH)(this.betaConstraint),gammaConstraint:(0,N.uH)(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}return i.className="BatchNormalization",i})();r.JFn.registerClass(we);let ze=(()=>{class i extends f.Wd{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=(0,z.Fe)(t.betaInitializer||"zeros"),this.gammaInitializer=(0,z.Fe)(t.gammaInitializer||"ones"),this.betaRegularizer=(0,C.Bm)(t.betaRegularizer),this.gammaRegularizer=(0,C.Bm)(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=(0,c.U$)(t)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let o=0;o<this.axis.length;++o)this.axis[o]<0&&(this.axis[o]+=e);for(const o of this.axis)if(o<0||o>=e)throw new Error(`Invalid axis: ${o}`);if(this.axis.length!==D.Am(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const s=this.axis.map(o=>t[o]),a=!0;this.gamma=this.scale?this.addWeight("gamma",s,"float32",this.gammaInitializer,this.gammaRegularizer,a):null,this.beta=this.center?this.addWeight("beta",s,"float32",this.betaInitializer,this.betaRegularizer,a):null,this.built=!0}call(t,e){const s=(0,c.un)(t),a=s.shape,o=a.length;return(0,r.DZQ)(()=>{let{mean:p,variance:g}=(0,r.Clk)(s,this.axis,!0);const b=D.fD(1,o);for(const V of this.axis)b[V]=a[V];const E=V=>null!=V&&V.shape.length!==o?r.tQQ(V,b):V;let k=this.scale?E(this.gamma.read()):null,O=this.center?E(this.beta.read()):null;const _=[],tt=[];for(let V=0;V<o;++V)-1!==this.axis.indexOf(V)?(_.push(a[V]),tt.push(1)):(_.push(1),tt.push(a[V]));return p=r.Vsq(p,_),g=r.Vsq(g,_),null!=k&&(k=r.Vsq(k,tt)),null!=O&&(O=r.Vsq(O,tt)),It(s,p,g,O,k,this.epsilon)})}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:(0,z.zo)(this.betaInitializer),gammaInitializer:(0,z.zo)(this.gammaInitializer),betaRegularizer:(0,C.R9)(this.betaRegularizer),gammaRegularizer:(0,C.R9)(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}return i.className="LayerNormalization",i})();r.JFn.registerClass(ze);let Ce=(()=>{class i extends f.Wd{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?(0,rt.VI)():t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new m.Qp(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,s;if("number"==typeof t.padding[0])e=[t.padding[0],t.padding[0]],s=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new m.Qp(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new m.Qp(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);s=t.padding[1]}this.padding=[e,s]}this.inputSpec=[new f.eO({ndim:4})]}computeOutputShape(t){let e,s;return t=(0,c.U$)(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,s=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,s]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,s=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,s,t[3]])}call(t,e){return(0,r.DZQ)(()=>function ss(i,n,t){return(0,r.DZQ)(()=>{if(4!==i.rank)throw new m.Qp(`temporalPadding expects input tensor to be 4-D, but received a ${i.rank}-D tensor.`);if(null==n&&(n=[[1,1],[1,1]]),2!==n.length||2!==n[0].length||2!==n[1].length)throw new m.Qp("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==t&&(t=(0,rt.VI)()),"channelsLast"!==t&&"channelsFirst"!==t)throw new m.Qp(`Unknown data format: ${t}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let e;return e="channelsFirst"===t?[[0,0],[0,0],n[0],n[1]]:[[0,0],n[0],n[1],[0,0]],r.eVF(i,e)})}((0,c.un)(t),this.padding,this.dataFormat))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}return i.className="ZeroPadding2D",i})();function kt(i,n,t,e,s,a){return(0,r.DZQ)(()=>{let o;(0,P.uM)(s),(0,P.Kx)(a),(0,P.tB)(e),null==t&&(t=[1,1]),null==e&&(e="valid"),null==s&&(s=(0,rt.VI)()),null==a&&(a="max"),i=h(i,s);const u="same"===e?"same":"valid";return o="max"===a?r.jgi(i,n,t,u):r.$jT(i,n,t,u),"channelsFirst"===s&&(o=r.mgz(o,[0,3,1,2])),o})}function ns(i,n,t,e,s,a){return(0,r.DZQ)(()=>{let o;(0,P.uM)(s),(0,P.Kx)(a),(0,P.tB)(e),null==t&&(t=[1,1,1]),null==e&&(e="valid"),null==s&&(s=(0,rt.VI)()),null==a&&(a="max"),i=v(i,s);const u="same"===e?"same":"valid";return o="max"===a?r.NYV(i,n,t,u):r.sub(i,n,t,u),"channelsFirst"===s&&(o=r.mgz(o,[0,4,1,2,3])),o})}r.JFn.registerClass(Ce);class Ae extends f.Wd{constructor(n){if(null==n.poolSize&&(n.poolSize=2),super(n),"number"==typeof n.poolSize)this.poolSize=[n.poolSize];else{if(!Array.isArray(n.poolSize)||1!==n.poolSize.length||"number"!=typeof n.poolSize[0])throw new m.Qp(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(n.poolSize)}`);this.poolSize=n.poolSize}if((0,D.oo)(this.poolSize,"poolSize"),null==n.strides)this.strides=this.poolSize;else if("number"==typeof n.strides)this.strides=[n.strides];else{if(!Array.isArray(n.strides)||1!==n.strides.length||"number"!=typeof n.strides[0])throw new m.Qp(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(n.strides)}`);this.strides=n.strides}(0,D.oo)(this.strides,"strides"),this.padding=null==n.padding?"valid":n.padding,(0,P.tB)(this.padding),this.inputSpec=[new f.eO({ndim:3})]}computeOutputShape(n){n=(0,c.U$)(n);const t=(0,Y.Ol)(n[1],this.poolSize[0],this.padding,this.strides[0]);return[n[0],t,n[2]]}call(n,t){return(0,r.DZQ)(()=>{this.invokeCallHook(n,t),n=x.UG((0,c.un)(n),2);const e=this.poolingFunction((0,c.un)(n),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return r.r2V(e,[2])})}getConfig(){const n={poolSize:this.poolSize,padding:this.padding,strides:this.strides},t=super.getConfig();return Object.assign(n,t),n}}r.JFn.registerClass((()=>{class i extends Ae{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),kt(t,e,s,a,o,"max")}}return i.className="MaxPooling1D",i})()),r.JFn.registerClass((()=>{class i extends Ae{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),kt(t,e,s,a,o,"avg")}}return i.className="AveragePooling1D",i})());class Ie extends f.Wd{constructor(n){if(null==n.poolSize&&(n.poolSize=[2,2]),super(n),this.poolSize=Array.isArray(n.poolSize)?n.poolSize:[n.poolSize,n.poolSize],null==n.strides)this.strides=this.poolSize;else if(Array.isArray(n.strides)){if(2!==n.strides.length)throw new m.Qp(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${n.strides.length}.`);this.strides=n.strides}else this.strides=[n.strides,n.strides];(0,D.oo)(this.poolSize,"poolSize"),(0,D.oo)(this.strides,"strides"),this.padding=null==n.padding?"valid":n.padding,this.dataFormat=null==n.dataFormat?"channelsLast":n.dataFormat,(0,P.uM)(this.dataFormat),(0,P.tB)(this.padding),this.inputSpec=[new f.eO({ndim:4})]}computeOutputShape(n){n=(0,c.U$)(n);let t="channelsFirst"===this.dataFormat?n[2]:n[1],e="channelsFirst"===this.dataFormat?n[3]:n[2];return t=(0,Y.Ol)(t,this.poolSize[0],this.padding,this.strides[0]),e=(0,Y.Ol)(e,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[n[0],n[1],t,e]:[n[0],t,e,n[3]]}call(n,t){return(0,r.DZQ)(()=>(this.invokeCallHook(n,t),this.poolingFunction((0,c.un)(n),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const n={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(n,t),n}}r.JFn.registerClass((()=>{class i extends Ie{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),kt(t,e,s,a,o,"max")}}return i.className="MaxPooling2D",i})()),r.JFn.registerClass((()=>{class i extends Ie{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),kt(t,e,s,a,o,"avg")}}return i.className="AveragePooling2D",i})());class Ee extends f.Wd{constructor(n){if(null==n.poolSize&&(n.poolSize=[2,2,2]),super(n),this.poolSize=Array.isArray(n.poolSize)?n.poolSize:[n.poolSize,n.poolSize,n.poolSize],null==n.strides)this.strides=this.poolSize;else if(Array.isArray(n.strides)){if(3!==n.strides.length)throw new m.Qp(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${n.strides.length}.`);this.strides=n.strides}else this.strides=[n.strides,n.strides,n.strides];(0,D.oo)(this.poolSize,"poolSize"),(0,D.oo)(this.strides,"strides"),this.padding=null==n.padding?"valid":n.padding,this.dataFormat=null==n.dataFormat?"channelsLast":n.dataFormat,(0,P.uM)(this.dataFormat),(0,P.tB)(this.padding),this.inputSpec=[new f.eO({ndim:5})]}computeOutputShape(n){n=(0,c.U$)(n);let t="channelsFirst"===this.dataFormat?n[2]:n[1],e="channelsFirst"===this.dataFormat?n[3]:n[2],s="channelsFirst"===this.dataFormat?n[4]:n[3];return t=(0,Y.Ol)(t,this.poolSize[0],this.padding,this.strides[0]),e=(0,Y.Ol)(e,this.poolSize[1],this.padding,this.strides[1]),s=(0,Y.Ol)(s,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[n[0],n[1],t,e,s]:[n[0],t,e,s,n[4]]}call(n,t){return(0,r.DZQ)(()=>(this.invokeCallHook(n,t),this.poolingFunction((0,c.un)(n),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const n={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(n,t),n}}r.JFn.registerClass((()=>{class i extends Ee{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),ns(t,e,s,a,o,"max")}}return i.className="MaxPooling3D",i})()),r.JFn.registerClass((()=>{class i extends Ee{constructor(t){super(t)}poolingFunction(t,e,s,a,o){return(0,P.uM)(o),(0,P.tB)(a),ns(t,e,s,a,o,"avg")}}return i.className="AveragePooling3D",i})());class Fe extends f.Wd{constructor(n){super(n),this.inputSpec=[new f.eO({ndim:3})]}computeOutputShape(n){return[n[0],n[2]]}call(n,t){throw new m.EH}}let Me=(()=>{class i extends Fe{constructor(t){super(t||{})}call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t);return r.i2o(s,1)})}}return i.className="GlobalAveragePooling1D",i})();r.JFn.registerClass(Me);let Le=(()=>{class i extends Fe{constructor(t){super(t||{})}call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t);return r.T9B(s,1)})}}return i.className="GlobalMaxPooling1D",i})();r.JFn.registerClass(Le);class ke extends f.Wd{constructor(n){super(n),this.dataFormat=null==n.dataFormat?"channelsLast":n.dataFormat,(0,P.uM)(this.dataFormat),this.inputSpec=[new f.eO({ndim:4})]}computeOutputShape(n){return"channelsLast"===this.dataFormat?[n[0],n[3]]:[n[0],n[1]]}call(n,t){throw new m.EH}getConfig(){const n={dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(n,t),n}}let Oe=(()=>{class i extends ke{call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t);return r.i2o(s,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}return i.className="GlobalAveragePooling2D",i})();r.JFn.registerClass(Oe);let Be=(()=>{class i extends ke{call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t);return r.T9B(s,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}return i.className="GlobalMaxPooling2D",i})();r.JFn.registerClass(Be);var is=l(89893);class Pe extends f.Wd{constructor(n){super(n),this.layer=n.layer}build(n){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(n){null!=this.layer&&(this.layer.trainable=n)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(n){this.layer.setWeights(n)}getConfig(){const n={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},t=super.getConfig();return Object.assign(n,t),n}setFastWeightInitDuringBuild(n){super.setFastWeightInitDuringBuild(n),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(n)}static fromConfig(n,t,e={}){const a=(0,At.i)(t.layer,e);delete t.layer;const o={layer:a};return Object.assign(o,t),new n(o)}}r.JFn.registerClass((()=>{class i extends Pe{constructor(t){super(t),this.supportsMasking=!0}build(t){if((t=(0,c.U$)(t)).length<3)throw new m.Qp(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){const e=[(t=(0,c.U$)(t))[0]].concat(t.slice(2)),s=this.layer.computeOutputShape(e);return[s[0],t[1]].concat(s.slice(1))}call(t,e){return(0,r.DZQ)(()=>ee((u,p)=>[(0,c.un)(this.layer.call(u,e)),[]],t=(0,c.un)(t),[],!1,null,null,!1,!0)[1])}}return i.className="TimeDistributed",i})());let Qe=(()=>{class i extends Pe{constructor(t){super(t);const e=t.layer.getConfig(),s={};s.className=t.layer.getClassName(),s.config=e,this.forwardLayer=(0,At.i)(s),e.goBackwards=!0!==e.goBackwards;const a={};if(a.className=t.layer.getClassName(),a.config=e,this.backwardLayer=(0,At.i)(a),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===t.mergeMode?"concat":t.mergeMode,function rs(i){D.E6(is.r$,"BidirectionalMergeMode",i)}(this.mergeMode),t.weights)throw new m.EH("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,null!=this.forwardLayer&&(this.forwardLayer.trainable=t),null!=this.backwardLayer&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const s=Math.floor(t.length/2);this.forwardLayer.setWeights(t.slice(0,s)),this.backwardLayer.setWeights(t.slice(s))}computeOutputShape(t){let s,a,o,e=this.forwardLayer.computeOutputShape(t);return Array.isArray(e)&&Array.isArray(e[0])||(e=[e]),this.returnState&&(o=e.slice(1)),s=e[0],"concat"===this.mergeMode?(s[s.length-1]*=2,a=[s]):a=null==this.mergeMode?[s,s.slice()]:[s],this.returnState?null==this.mergeMode?a.concat(o).concat(o.slice()):[s].concat(o).concat(o.slice()):D.wL(a)}apply(t,e){let s=null==e?null:e.initialState,a=null==e?null:e.constants;null==e&&(e={});const o=te(t,s,a,this.numConstants);if(t=o.inputs,s=o.initialState,a=o.constants,Array.isArray(t)&&(s=t.slice(1),t=t[0]),(null==s||0===s.length)&&null==a)return super.apply(t,e);const u=[],p=[];if(null!=s){const b=s.length;if(b%2>0)throw new m.Qp("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=s,u.push(...s);const E=s.map(k=>new f.eO({shape:k.shape}));this.forwardLayer.stateSpec=E.slice(0,b/2),this.backwardLayer.stateSpec=E.slice(b/2),p.push(...E)}if(null!=a)throw new m.EH("Support for constants in Bidirectional layers is not implemented yet.");const g=u[0]instanceof f.Ar;for(const b of u)if(b instanceof f.Ar!==g)throw new m.Qp("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(g){const b=[t].concat(u),E=this.inputSpec.concat(p),k=this.inputSpec;this.inputSpec=E;const O=super.apply(b,e);return this.inputSpec=k,O}return super.apply(t,e)}call(t,e){return(0,r.DZQ)(()=>{const s=e.initialState;let a,o,u,p;if(null==s)a=this.forwardLayer.call(t,e),o=this.backwardLayer.call(t,e);else{const g=s.slice(0,s.length/2),b=s.slice(s.length/2);a=this.forwardLayer.call(t,Object.assign(e,{initialState:g})),o=this.backwardLayer.call(t,Object.assign(e,{initialState:b}))}return this.returnState&&(Array.isArray(a)&&(u=a.slice(1).concat(o.slice(1))),a=a[0],o=o[0]),this.returnSequences&&(o=r.BEg(o,1)),"concat"===this.mergeMode?p=x.u1([a,o]):"sum"===this.mergeMode?p=r.WQq(a,o):"ave"===this.mergeMode?p=r.lKK(.5,r.WQq(a,o)):"mul"===this.mergeMode?p=r.lKK(a,o):null==this.mergeMode&&(p=[a,o]),this.returnState?null==this.mergeMode?p.concat(u):[p].concat(u):p})}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){(0,P.IU)(this.forwardLayer.name,()=>{this.forwardLayer.build(t)}),(0,P.IU)(this.backwardLayer.name,()=>{this.backwardLayer.build(t)}),this.built=!0}computeMask(t,e){let s;if(Array.isArray(e)&&(e=e[0]),s=this.returnSequences?null==this.mergeMode?[e,e]:e:null==this.mergeMode?[null,null]:null,this.returnState){const o=this.forwardLayer.states.map(u=>null);return Array.isArray(s)?s.concat(o).concat(o):[s].concat(o).concat(o)}return s}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(t),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const s=(0,At.i)(e.layer);if(delete e.layer,null!=e.numConstants)throw new m.EH("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const a=e;return a.layer=s,new t(a)}}return i.className="Bidirectional",i})();r.JFn.registerClass(Qe),r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.scale=t.scale,this.offset=t.offset?t.offset:0}getConfig(){const t={scale:this.scale,offset:this.offset},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return(0,r.DZQ)(()=>("float32"!==(t=(0,c.un)(t)).dtype&&(t=x.wg(t,"float32")),(0,r.WQq)((0,r.lKK)(t,this.scale),this.offset)))}}return i.className="Rescaling",i})());const{resizeBilinear:os,cropAndResize:ls}=r.Slp;r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.height=t.height,this.width=t.width}centerCrop(t,e,s,a,o,u,p,g){return(0,r.DZQ)(()=>{let b,E=!1;const V=[e/u,s/p,(a+e)/u,(o+s)/p],J=[];3===t.rank?(E=!0,b=(0,r.t$z)([t])):b=t;for(let dt=0;dt<b.shape[0];dt++)J.push(V);const at=(0,r.OEK)(J,[J.length,4]),lt=(0,r.y17)(0,J.length,1,"int32"),ht=ls(b,at,lt,[a,o],"nearest");return x.wg(E?(0,c.un)((0,r.K$i)(ht)):ht,g)})}upsize(t,e,s,a){return(0,r.DZQ)(()=>{const o=os(t,[e,s]);return x.wg(o,a)})}call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t),a=s.dtype,o=s.shape,u=o[o.length-3],p=o[o.length-2];let g=0;u!==this.height&&(g=Math.floor((u-this.height)/2));let b=0;return p!==this.width&&(b=Math.floor((p-this.width)/2),0===b&&(b=1)),g>=0&&b>=0?this.centerCrop(s,g,b,this.height,this.width,u,p,a):this.upsize(t,this.height,this.width,a)})}getConfig(){const t={height:this.height,width:this.width},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){const s=(t=(0,c.U$)(t)).length-2;return t[t.length-3]=this.height,t[s]=this.width,t}}return i.className="CenterCrop",i})());var us=l(97301);r.JFn.registerClass((()=>{class i extends f.Wd{constructor(t){super(t),this.numTokens=t.numTokens,this.outputMode=t.outputMode?t.outputMode:"multiHot"}getConfig(){const t={numTokens:this.numTokens,outputMode:this.outputMode},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){return null==(t=(0,c.U$)(t))?[this.numTokens]:"oneHot"===this.outputMode&&1!==t[t.length-1]?(t.push(this.numTokens),t):(t[t.length-1]=this.numTokens,t)}call(t,e){return(0,r.DZQ)(()=>{let s;if("int32"!==(t=(0,c.un)(t)).dtype&&(t=x.wg(t,"int32")),typeof e.countWeights<"u"){if("count"!==this.outputMode)throw new m.Qp(`countWeights is not used when outputMode !== count.\n              Received countWeights=${e.countWeights}`);s=(0,c.un)(e.countWeights)}const a=(0,r.T9B)(t),o=(0,r.jkA)(t),u=(0,r.rhj)(this.numTokens,a).bufferSync().get(0),p=(0,r.DQN)(o,0).bufferSync().get(0);if(!u||!p)throw new m.Qp(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);return us.w(t,this.outputMode,this.numTokens,s)})}}return i.className="CategoryEncoding",i})());const je=new Set(["bilinear","nearest"]);let Ke=(()=>{class i extends f.Wd{constructor(t){if(super(t),this.height=t.height,this.width=t.width,t.interpolation){if(!je.has(t.interpolation))throw new m.Qp(`Invalid interpolation parameter: ${t.interpolation} is not implemented`);this.interpolation=t.interpolation}else this.interpolation="bilinear";this.cropToAspectRatio=!!t.cropToAspectRatio}computeOutputShape(t){return t=(0,c.U$)(t),[this.height,this.width,t[2]]}getConfig(){const t={height:this.height,width:this.width,interpolation:this.interpolation,cropToAspectRatio:this.cropToAspectRatio},e=super.getConfig();return Object.assign(t,e),t}call(t,e){return(0,r.DZQ)(()=>{const s=[this.height,this.width];if("bilinear"===this.interpolation)return r.Slp.resizeBilinear(t,s,!this.cropToAspectRatio);if("nearest"===this.interpolation)return r.Slp.resizeNearestNeighbor(t,s,!this.cropToAspectRatio);throw new Error(`Interpolation is ${this.interpolation} but only ${[...je]} are supported`)})}}return i.className="Resizing",i})();r.JFn.registerClass(Ke);var cs=l(29947);const He=new Set(["bilinear","nearest"]);let Ge=(()=>{class i extends cs.W{constructor(t){super(t);const{factor:e,interpolation:s="bilinear"}=t;if(this.factor=e,Array.isArray(this.factor)&&2===this.factor.length)this.widthLower=this.factor[0],this.widthUpper=this.factor[1];else{if(Array.isArray(this.factor)||!(this.factor>0))throw new m.Qp(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);this.widthLower=-this.factor,this.widthUpper=this.factor}if(this.widthLower<-1||this.widthUpper<-1)throw new m.Qp(`factor must have values larger than -1. Got: ${this.factor}`);if(this.widthUpper<this.widthLower)throw new m.Qp(`factor cannot have upper bound less than lower bound.\n        Got upper bound: ${this.widthUpper}.\n        Got lower bound: ${this.widthLower}\n      `);if(s){if(!He.has(s))throw new m.Qp(`Invalid interpolation parameter: ${s} is not implemented`);this.interpolation=s}}getConfig(){const t={factor:this.factor,interpolation:this.interpolation},e=super.getConfig();return Object.assign(t,e),t}computeOutputShape(t){return t=(0,c.U$)(t),[this.imgHeight,-1,t[2]]}call(t,e){return(0,r.DZQ)(()=>{const s=(0,c.un)(t);this.imgHeight=s.shape[s.shape.length-3];const a=s.shape[s.shape.length-2];this.widthFactor=(0,r.YeY)([1],1+this.widthLower,1+this.widthUpper,"float32",this.randomGenerator.next());let o=this.widthFactor.dataSync()[0]*a;o=Math.round(o);const u=[this.imgHeight,o];switch(this.interpolation){case"bilinear":return r.Slp.resizeBilinear(t,u);case"nearest":return r.Slp.resizeNearestNeighbor(t,u);default:throw new Error(`Interpolation is ${this.interpolation}\n          but only ${[...He]} are supported`)}})}}return i.className="RandomWidth",i})();function ct(i){return new oe(i)}r.JFn.registerClass(Ge),l(39416),l(40183),l(73112),l(30593),l(13509),l(30744);var Fn=l(48814),Rt=l(74042),Qs=l(27669);let Us=(()=>{class i{constructor(){this.size=null}batch(t,e=!0){const s=this;let a;return r.ZSL.assert(t>0,()=>`batchSize needs to be positive, but it is\n      ${t}`),a=this.size===1/0||null==this.size?this.size:e?Math.ceil(this.size/t):Math.floor(this.size/t),ft((0,y.A)(function*(){return(yield s.iterator()).columnMajorBatch(t,e,Mn)}),a)}concatenate(t){const e=this;let s;return s=this.size===1/0||t.size===1/0?1/0:null!=this.size&&null!=t.size?this.size+t.size:null,ft((0,y.A)(function*(){return(yield e.iterator()).concatenate(yield t.iterator())}),s)}filter(t){const e=this;let s;return s=this.size===1/0?1/0:null,ft((0,y.A)(function*(){return(yield e.iterator()).filter(a=>r.DZQ(()=>t(a)))}),s)}forEachAsync(t){var e=this;return(0,y.A)(function*(){return(yield e.iterator()).forEachAsync(t)})()}map(t){const e=this;return ft((0,y.A)(function*(){return(yield e.iterator()).map(s=>r.DZQ(()=>t(s)))}),this.size)}mapAsync(t){const e=this;return ft((0,y.A)(function*(){return(yield e.iterator()).mapAsync(t)}),this.size)}prefetch(t){if(null==t)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const e=this;return ft((0,y.A)(function*(){return(yield e.iterator()).prefetch(t)}),this.size)}repeat(t){const e=this;let s;return s=null!=this.size&&t>0?this.size*t:0===t?0:null!=this.size&&(void 0===t||t<0)?1/0:null,ft((0,y.A)(function*(){const a=(0,Rt.ht)((0,y.A)(function*(){return{value:yield e.iterator(),done:!1}}));return(0,Rt.kP)(a.take(t))}),s)}skip(t){const e=this;let s;return s=null!=this.size&&t>=0&&this.size>=t?this.size-t:null!=this.size&&(this.size<t||void 0===t||t<0)?0:null,ft((0,y.A)(function*(){return(yield e.iterator()).skip(t)}),s)}shuffle(t,e,s=!0){if(null==t||t<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const a=this,o=Fn.alea(e||r.ZSL.now().toString());return ft((0,y.A)(function*(){let u=o.int32();return s&&(u+=o.int32()),(yield a.iterator()).shuffle(t,u.toString())}),this.size)}take(t){const e=this;let s;return s=null!=this.size&&this.size>t?t:null!=this.size&&this.size<=t?this.size:null,ft((0,y.A)(function*(){return(yield e.iterator()).take(t)}),s)}toArray(){var t=this;return(0,y.A)(function*(){if(t.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(yield t.iterator()).toArray()})()}toArrayForTest(){var t=this;return(0,y.A)(function*(){if(t.size===1/0)throw new Error("Can not convert infinite data stream to array.");return(yield t.iterator()).toArrayForTest()})()}}return i.MAX_BUFFER_SIZE=1e4,i})();function ft(i,n=null){return new class extends Us{constructor(){super(...arguments),this.size=n}iterator(){return(0,y.A)(function*(){return i()})()}}}function Mn(i){return null===i?null:(0,Qs.mf)(i[0])?{value:Ln(i),recurse:!1}:{value:null,recurse:!0}}function Ln(i){if(0===i.length)throw new Error("Can't make a batch of zero elements.");return i[0]instanceof r.qYS?r.t$z(i):r.OEK(i)}Symbol("out"),Symbol("field"),Symbol("quote"),Symbol("quoteafterquote"),Symbol("quoteinquote"),l(4902),l(11033),l(41014),l(8084),l(98603),l(21750),l(22412),l(77816);function sn(){return(sn=(0,y.A)(function*(){const n=yield(yield fetch("/one-more-battery/assets/data/mnist_images.png")).blob(),t=yield createImageBitmap(n),e=yield fetch("/one-more-battery/assets/data/mnist_labels_uint8"),s=new Uint8Array(yield e.arrayBuffer()),a=s.length,o=new Float32Array(28*a*28),p=new OffscreenCanvas(28,28).getContext("2d"),g=Math.floor(t.width/28);for(let b=0;b<a;b++){const E=28*b*28,k=Math.floor(b/g);p.drawImage(t,b%g*28,28*k,28,28,0,0,28,28);const V=p.getImageData(0,0,28,28);for(let J=0;J<V.data.length/4;J++)o[E+J]=V.data[4*J]/255}return{images:o,labels:s}})).apply(this,arguments)}addEventListener("message",function(){var i=(0,y.A)(function*({}){try{(yield l.e(2719).then(l.bind(l,22719))).setWasmPaths({"tfjs-backend-wasm.wasm":"/one-more-battery/assets/wasm/tfjs-backend-wasm.wasm","tfjs-backend-wasm-simd.wasm":"/one-more-battery/assets/wasm/tfjs-backend-wasm.wasm","tfjs-backend-wasm-threaded-simd.wasm":"/one-more-battery/assets/wasm/tfjs-backend-wasm.wasm"}),r._K2().set("WASM_HAS_SIMD_SUPPORT",!1);const g=yield r._K2().getAsync("WASM_HAS_MULTITHREAD_SUPPORT"),b=yield r._K2().getAsync("WASM_HAS_SIMD_SUPPORT");postMessage({type:"log",message:`WASM multithreading support: ${g}`}),postMessage({type:"log",message:`WASM SIMD support: ${b}`}),yield r.jh6("wasm"),yield r.Gc4(),postMessage({type:"log",message:`\u2705 Using backend: ${r.jz4()}`})}catch(p){postMessage({type:"log",message:`\u26a0\ufe0f WASM backend not available, falling back to CPU: ${p}`}),yield r.jh6("cpu"),yield r.Gc4(),postMessage({type:"log",message:"\u2705 Using CPU backend."})}postMessage({type:"log",message:"Backend set."}),postMessage({type:"log",message:"Loading data..."});const t=performance.now(),{images:e,labels:s}=yield function Hn(){return sn.apply(this,arguments)}(),a=performance.now();postMessage({type:"log",message:`Data loaded in ${(a-t).toFixed(2)} ms.`}),postMessage({type:"log",message:"Creating model..."});const o=function Vn(){const i=function H(i){return new nt.Gx(i)}();return i.add(function ps(i){return new le(i)}({inputShape:[28,28]})),i.add(ct({units:128,activation:"relu",kernelInitializer:"varianceScaling"})),i.add(ct({units:10,kernelInitializer:"varianceScaling",activation:"softmax"})),i.compile({optimizer:r.BaG.adam(),loss:"categoricalCrossentropy",metrics:["accuracy"]}),i}();postMessage({type:"log",message:"Model created."}),postMessage({type:"log",message:"Starting training..."});const u=function Un(i){return ft((0,y.A)(function*(){const n=yield i();return(0,Rt.ht)(()=>n.next())}))}(()=>function*Gn(i,n){const t=n.length;for(let e=0;e<t;e++){const s=28*e*28,a=i.slice(s,s+784),o=r.KtR(a,[28,28]).reshape([1,28,28]),u=r.Mw0(r.tGX([n[e]],"int32"),10).squeeze();yield{xs:o,ys:u}}}(e,s)).shuffle(1e3).batch(512);yield o.fitDataset(u,{epochs:20,callbacks:{onEpochEnd:(p,g)=>{p%5==0&&postMessage({type:"log",message:`Epoch ${p+1}: loss = ${g.loss.toFixed(4)}, acc = ${g.acc.toFixed(4)}`})}}}),postMessage({type:"log",message:"Training complete."}),yield o.save("downloads://model"),postMessage({type:"done"})});return function(n){return i.apply(this,arguments)}}())},47054:(I,Q,l)=>{"use strict";l.d(Q,{AS:()=>H,DZ:()=>S,Gc:()=>N,Hi:()=>L,Hs:()=>B,aC:()=>U,fL:()=>M,gJ:()=>T,jh:()=>K,jz:()=>m,m1:()=>W});var y=l(611),r=l(25271),F=l(73444),$=l(14548);function M(Z){(0,r._K)().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(Z+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function L(){return y.T2}function W(){return y.T2.memory()}function S(Z,q){return y.T2.tidy(Z,q)}function H(Z){(0,$.getTensorsInContainer)(Z).forEach(ot=>ot.dispose())}function U(Z){return y.T2.keep(Z)}function K(Z){return y.T2.setBackend(Z)}function N(){return y.T2.ready()}function m(){return y.T2.backendName}function T(Z,q,ot=1){return y.T2.registerBackend(Z,q,ot)}function B(){return y.T2.backend}(0,F.B4)(M)},41653:(I,Q,l)=>{"use strict";l.d(Q,{ljI:()=>d.ljI,Vvy:()=>d.Vvy,PH8:()=>d.PH8,OMN:()=>d.OMN,EkD:()=>d.EkD,u8Z:()=>d.u8Z,FSt:()=>d.FSt,Jp_:()=>d.Jp_,p_m:()=>d.p_m,QKF:()=>d.QKF,epO:()=>d.epO,TyE:()=>d.TyE,lxb:()=>d.lxb,zP9:()=>d.zP9,ho8:()=>d.ho8,cS:()=>d.cS,wwC:()=>d.wwC,VCH:()=>d.VCH,jAQ:()=>d.jAQ,Ik2:()=>d.Ik2,N4F:()=>d.N4F,HNs:()=>d.HNs,vj7:()=>d.vj7,KXH:()=>d.KXH,QDP:()=>d.QDP,vaV:()=>d.vaV,pr3:()=>d.pr3,$zE:()=>d.$zE,$dB:()=>d.$dB,p2J:()=>d.p2J,rFm:()=>d.rFm,jfg:()=>d.jfg,A1h:()=>d.A1h,iGz:()=>d.iGz,gC7:()=>d.gC7,Mn0:()=>d.Mn0,MnK:()=>d.MnK,MRQ:()=>d.MRQ,jj_:()=>d.jj_,nY8:()=>d.nY8,GJx:()=>fs.GJ,wNW:()=>d.wNW,TMz:()=>d.TMz,tGH:()=>d.tGH,X$8:()=>d.X$8,nVu:()=>d.nVu,ORI:()=>d.ORI,jxD:()=>d.jxD,pk0:()=>d.pk0,bP9:()=>d.bP9,XmO:()=>d.XmO,Qgm:()=>d.Qgm,Pah:()=>d.Pah,rsH:()=>d.rsH,BRl:()=>d.BRl,_s9:()=>d._s9,ox3:()=>d.ox3,ybN:()=>d.ybN,ybj:()=>d.ybj,rGP:()=>d.rGP,SQl:()=>d.SQl,BxF:()=>d.BxF,ZgB:()=>d.ZgB,ElG:()=>d.ElG,awo:()=>d.awo,i5R:()=>d.i5R,aAr:()=>d.aAr,T7M:()=>d.T7M,O4G:()=>d.O4G,mxL:()=>d.mxL,XhZ:()=>d.XhZ,lLS:()=>d.lLS,OAQ:()=>d.OAQ,lzr:()=>d.lzr,dv8:()=>d.dv8,gIW:()=>d.gIW,E3$:()=>d.E3$,iPs:()=>d.iPs,uI_:()=>fs.uI,jM4:()=>d.jM4,ToN:()=>d.ToN,X0$:()=>d.X0$,mIA:()=>d.mIA,CwD:()=>d.CwD,mnI:()=>d.mnI,tG8:()=>d.tG8,Cg$:()=>d.Cg$,RUm:()=>d.RUm,nZd:()=>d.nZd,LXA:()=>d.LXA,RW8:()=>d.RW8,VAI:()=>d.VAI,t3d:()=>d.t3d,ySp:()=>d.ySp,cHb:()=>d.cHb,RXX:()=>d.RXX,TL8:()=>d.TL8,LDN:()=>d.LDN,g5A:()=>d.g5A,lNG:()=>d.lNG,LG0:()=>d.LG0,x7F:()=>d.x7F,BLA:()=>d.BLA,WT3:()=>d.WT3,xu7:()=>d.xu7,l0G:()=>d.l0G,SDM:()=>d.SDM,Zl4:()=>d.Zl4,e0f:()=>d.e0f,ylV:()=>d.ylV,urI:()=>d.urI,LWX:()=>d.LWX,ELo:()=>S.E,mM$:()=>d.mM$,ODT:()=>d.ODT,pyJ:()=>d.pyJ,Ncv:()=>d.Ncv,kdj:()=>d.kdj,oJ2:()=>d.oJ2,CQC:()=>d.CQC,mH5:()=>d.mH5,Q6t:()=>d.Q6t,LRy:()=>d.LRy,sDr:()=>d.sDr,huO:()=>d.huO,fUj:()=>d.fUj,P_L:()=>d.P_L,R23:()=>d.R23,hgw:()=>d.hgw,FCQ:()=>d.FCQ,jOE:()=>d.jOE,XQy:()=>d.XQy,D7i:()=>d.D7i,BK4:()=>d.BK4,hVg:()=>d.hVg,TOR:()=>d.TOR,pJc:()=>d.pJc,uWl:()=>d.uWl,l6P:()=>d.l6P,u$b:()=>d.u$b,vI1:()=>d.vI1,YVe:()=>d.YVe,hql:()=>d.hql,J3C:()=>d.J3C,JiE:()=>d.JiE,rFG:()=>d.rFG,Fin:()=>d.Fin,A8B:()=>d.A8B,C8s:()=>d.C8s,BoJ:()=>d.BoJ,L6G:()=>d.L6G,DvZ:()=>d.DvZ,jgd:()=>d.jgd,Blb:()=>d.Blb,dFH:()=>d.dFH,M6A:()=>d.M6A,Ddj:()=>d.Ddj,GZp:()=>d.GZp,pnw:()=>d.pnw,UcO:()=>d.UcO,YAb:()=>d.YAb,iW0:()=>d.iW0,$jE:()=>d.$jE,PbM:()=>d.PbM,WuN:()=>d.WuN,oFs:()=>d.oFs,iuW:()=>d.iuW,qYS:()=>H.qY,ylz:()=>H.yl,X4r:()=>d.X4r,FAs:()=>d.FAs,TBb:()=>d.TBb,dLy:()=>d.dLy,wx0:()=>d.wx0,EwU:()=>d.EwU,dXR:()=>d.dXR,pPe:()=>d.pPe,xJ3:()=>d.xJ3,Dr:()=>d.Dr,tnl:()=>it.t,WQq:()=>K.W,Q7R:()=>N.Q,bzn:()=>m.b,FLi:()=>z.F,$jT:()=>C.$,sub:()=>c.s,Hs:()=>ct.Hs,C0T:()=>Ps,BFc:()=>T.B,kSi:()=>B.k,T5N:()=>X.T,hOW:()=>Z.h,ZEY:()=>$,TaL:()=>A,ra8:()=>q.r,wgE:()=>ot.w,zQh:()=>rt.z,o8B:()=>x.o,xWs:()=>P.x,I1m:()=>Y.I,RPU:()=>D.R,O5O:()=>h.O,P1l:()=>v.P,kA9:()=>j.k,Xtf:()=>st.X,wX9:()=>pt.w,IPL:()=>ut.I,jIJ:()=>Ot.j,aOp:()=>Bt.a,fLc:()=>ct.fL,Gl3:()=>wt.G,eMq:()=>Ws,ASo:()=>ct.AS,y4m:()=>Ct.y,EZY:()=>kt.E,Pqc:()=>Pt.P,Hi9:()=>ct.Hi,_K2:()=>Bs._K,LCg:()=>Wt.L,Y12:()=>Ht.Y,oNF:()=>Gt.o,UG6:()=>Ve.U,y5U:()=>Vt.y,GSj:()=>Jt.G,RIf:()=>Xt.R,cZk:()=>Ie,kgh:()=>Yt.k,FJy:()=>R,jz4:()=>ct.jz,rhj:()=>Je.r,DQN:()=>qt.D,Slp:()=>Ms,io:()=>F,aCs:()=>ct.aC,kpo:()=>Xs,H8d:()=>et.H,mPL:()=>Ls,Rm2:()=>_t.R,Kko:()=>At.K,HPB:()=>te.H,VZ:()=>ee.V,n76:()=>Dt.n,NoW:()=>xt.N,T9B:()=>Qt.T,jgi:()=>se.j,NYV:()=>Ut.e,PhQ:()=>ne.P,i2o:()=>Et.i,m1Z:()=>ct.m1,jkA:()=>ie.j,BpO:()=>$t.B,Clk:()=>vt.C,lKK:()=>Xe.l,HZy:()=>ys.H,dA1:()=>ps.d,Ec:()=>Ye.E,Mw0:()=>Zt.M,SaS:()=>re.S,P61:()=>jt.P,eVF:()=>ae.e,n7C:()=>oe.n,NsG:()=>le.N,FE$:()=>ue.F,YeY:()=>he.Y,y17:()=>ce.y,Gc4:()=>ct.Gc,gJX:()=>ct.gJ,tAK:()=>Os.tA,VVh:()=>de.V,tQQ:()=>pe.t,BEg:()=>fe.B,d_2:()=>me.d,g23:()=>w,WfX:()=>zt.W,wdz:()=>Nt.w,JFn:()=>f,jh6:()=>ct.jh,ry7:()=>js.r,dik:()=>Tt.d,Q$M:()=>vs.Q,zAd:()=>Kt.z,wck:()=>bs.w,R0O:()=>Ft.R,Kro:()=>M,Vs9:()=>ws.V,lw0:()=>Mt.l,lDo:()=>zs.l,RZD:()=>Lt.R,r2V:()=>Cs.r,t$z:()=>St.t,jbE:()=>qe.j,czq:()=>ge.c,chL:()=>U.ch,ymU:()=>ye.y,OEK:()=>ve.O,tGX:()=>be.t,KtR:()=>It.K,d_S:()=>L,DZQ:()=>ct.DZ,Vsq:()=>_e.V,BaG:()=>ks.B,mgz:()=>Ce.m,efE:()=>ts.e,K$i:()=>es.K,TuY:()=>U.Tu,ZSL:()=>W,bvq:()=>we.b,bgA:()=>nt.r,_M9:()=>ze._,Ul9:()=>As.U,POl:()=>ss.P}),l(80225);var r=l(29609),F=l(3821),$=l(9269),A=l(25905),R=l(14146),w=l(17731),M=l(1986),f=l(1506),L=l(14548),W=l(21710),nt=l(97762),S=l(56188),H=l(73444),U=l(82891),it=l(72009),K=l(83034),N=l(56682),m=l(37547),z=l(71084),C=l(37434),c=l(36806),T=l(44353),B=l(46884),X=l(77807),Z=l(3752),q=l(75987),ot=l(92290),rt=l(70581),x=l(61548),P=l(35213),Y=l(35317),D=l(74810),h=l(36183),v=l(18380),j=l(53054),st=l(12809),pt=l(83521),ut=l(37740),Ot=l(2772),Bt=l(26193),wt=l(73595),Ct=l(4350),Pt=l(41325),Wt=l(68833),Ht=l(78650),Gt=l(68326),Ve=l(42103),Vt=l(45104),Jt=l(7684),Xt=l(41467),Yt=l(38837),Je=l(54807),qt=l(94300),et=l(93580),_t=l(8535),At=l(72954),te=l(89578),ee=l(17391),Dt=l(21292),xt=l(60314),Qt=l(56619),se=l(40044),Ut=l(42524),ne=l(74659),Et=l(23444),ie=l(82825),$t=l(85233),vt=l(11732),Xe=l(59731),ys=l(43267),Ye=l(66279),Zt=l(87073),re=l(95032),jt=l(28692),ae=l(54472),oe=l(53827),le=l(62655),ue=l(41222),he=l(65413),ce=l(16412),de=l(98611),pe=l(94399),fe=l(21067),me=l(10829),zt=l(26966),Nt=l(48285),js=l(53205),Tt=l(94063),vs=l(14638),Kt=l(81209),bs=l(29660),Ft=l(24167),ws=l(52431),Mt=l(14181),zs=l(91517),Lt=l(51583),Cs=l(41621),St=l(92885),qe=l(59279),ge=l(66342),ye=l(86580),ve=l(74544),be=l(48449),It=l(41494),_e=l(36409),ts=l(3609),es=l(48256),we=l(38121),ze=l(56914),As=l(20218),ss=l(44714),Ce=l(77914),kt=l(45733),Ie=(l(40638),l(90694),l(15245),l(43),l(63552)),Te=(l(79208),l(92822),l(32395),l(76221),l(27958)),Fe=l(99587),Me=l(60926),Le=l(70644),ke=l(76333),Oe=l(30561),Be=l(50110),is=l(31393),Pe=l(47774),We=l(4594),rs=l(33601),as=l(26486),Qe=l(91719),Ue=l(65425),os=l(59339),ls=l(55244),$e=l(52325),us=l(92974);l(88476),l(24782),l(36170),l(45026),l(29655),l(3733),l(33115),l(79780),l(33030),l(19702),l(56637),l(46764),l(46782),l(37500),l(74305),l(45629),l(41342);const Ms={flipLeftRight:Fe.n,grayscaleToRGB:Me.C,resizeNearestNeighbor:Qe.b,resizeBilinear:as.v,rgbToGrayscale:Le.S,rotateWithOffset:ke.x,cropAndResize:Te.C,nonMaxSuppression:Oe.L,nonMaxSuppressionAsync:Be.z,nonMaxSuppressionWithScore:is.f,nonMaxSuppressionWithScoreAsync:Pe.l,nonMaxSuppressionPadded:We.H,nonMaxSuppressionPaddedAsync:rs.R,threshold:Ue.E,transform:os.p},Ls={bandPart:ls.x,gramSchmidt:$e.i,qr:us.qr};var ks=l(19057),ct=l(47054),Os=l(56203),Bs=l(25271),ps=l(9173),Ps=l(90928),Ws=l(6757),Xs=l(89191),fs=l(86614),d=l(30162);(0,r.i)()},30162:(I,Q,l)=>{"use strict";l.d(Q,{$dB:()=>x,$jE:()=>Ls,$zE:()=>rt,A1h:()=>h,A8B:()=>He,BK4:()=>hn,BLA:()=>ve,BRl:()=>At,Blb:()=>Ge,BoJ:()=>Is,BxF:()=>se,C8s:()=>Ss,CQC:()=>Re,Cg$:()=>de,CwD:()=>ue,D7i:()=>Pe,Ddj:()=>Ns,Dr:()=>cn,DvZ:()=>xs,E3$:()=>jt,EkD:()=>A,ElG:()=>ne,EwU:()=>ps,FAs:()=>ks,FCQ:()=>Be,FSt:()=>w,Fin:()=>Ke,GZp:()=>Fs,HNs:()=>c,Ik2:()=>z,J3C:()=>Ze,JiE:()=>$e,Jp_:()=>M,KXH:()=>X,L6G:()=>Rs,LB5:()=>T,LDN:()=>Ft,LG0:()=>ge,LRy:()=>Ne,LWX:()=>As,LXA:()=>me,M6A:()=>Ts,MRQ:()=>Bt,Mn0:()=>st,MnK:()=>pt,N4F:()=>C,Ncv:()=>De,O4G:()=>$t,OAQ:()=>Ye,ODT:()=>kt,OMN:()=>$,ORI:()=>Gt,PH8:()=>F,P_L:()=>is,Pah:()=>qt,PbM:()=>Gs,Q6t:()=>Ee,QDP:()=>Z,QKF:()=>L,Qgm:()=>Je,R23:()=>Me,RUm:()=>pe,RW8:()=>zt,RXX:()=>Mt,SDM:()=>es,SQl:()=>Qt,T7M:()=>pn,TBb:()=>ct,TL8:()=>Cs,TMz:()=>Ct,TOR:()=>rs,ToN:()=>vs,TyE:()=>nt,UcO:()=>Ks,VAI:()=>bs,VCH:()=>it,Vvy:()=>r,WT3:()=>be,WuN:()=>ds,X$8:()=>Wt,X0$:()=>oe,X4r:()=>Qe,XQy:()=>ke,XhZ:()=>vt,XmO:()=>Xt,YAb:()=>Hs,YVe:()=>hs,ZgB:()=>Ut,Zl4:()=>we,_s9:()=>_t,aAr:()=>dn,awo:()=>un,bP9:()=>Vt,cHb:()=>Lt,cS:()=>K,dFH:()=>cs,dLy:()=>Os,dXR:()=>Ps,dv8:()=>Zt,e0f:()=>ze,epO:()=>W,fUj:()=>Fe,g5A:()=>St,gC7:()=>j,gIW:()=>re,hVg:()=>We,hgw:()=>Oe,ho8:()=>U,hql:()=>us,huO:()=>Te,i5R:()=>Et,iGz:()=>v,iPs:()=>ae,iW0:()=>Ms,iuW:()=>Js,jAQ:()=>m,jM4:()=>Tt,jOE:()=>Le,jfg:()=>D,jgd:()=>Es,jj_:()=>ut,jxD:()=>Ve,kdj:()=>Se,l0G:()=>_e,l6P:()=>os,lLS:()=>Xe,lNG:()=>qe,ljI:()=>y,lxb:()=>H,lzr:()=>ys,mH5:()=>xe,mIA:()=>le,mM$:()=>Ce,mnI:()=>he,mxL:()=>ie,nVu:()=>Ht,nY8:()=>Ot,nZd:()=>fe,oFs:()=>Vs,oJ2:()=>Ie,ox3:()=>te,p2J:()=>P,pJc:()=>as,pPe:()=>Ws,p_m:()=>f,pk0:()=>Jt,pnw:()=>d,pr3:()=>ot,pyJ:()=>Ae,rFG:()=>Ds,rFm:()=>Y,rGP:()=>xt,rsH:()=>et,sDr:()=>Yt,t3d:()=>ws,tG8:()=>ce,tGH:()=>Pt,u$b:()=>ls,u8Z:()=>R,uWl:()=>Ue,urI:()=>ss,vI1:()=>je,vaV:()=>q,vj7:()=>B,wNW:()=>wt,wwC:()=>N,wx0:()=>Bs,x7F:()=>ye,xJ3:()=>fs,xu7:()=>It,ySp:()=>zs,ybN:()=>ee,ybj:()=>Dt,ylV:()=>ts,zP9:()=>S,zfU:()=>Nt});const y="Abs",r="Acos",F="Acosh",$="Add",A="AddN",R="All",w="Any",M="ArgMax",f="ArgMin",L="Asin",W="Asinh",nt="Atan",S="Atanh",H="Atan2",U="AvgPool",it="AvgPoolGrad",K="AvgPool3D",N="AvgPool3DGrad",m="BatchMatMul",z="BatchToSpaceND",C="Bincount",c="BitwiseAnd",T="BroadcastTo",B="BroadcastArgs",X="Cast",Z="Ceil",q="ClipByValue",ot="Complex",rt="ComplexAbs",x="Concat",P="Conv2D",Y="Conv2DBackpropFilter",D="Conv2DBackpropInput",h="Conv3D",v="Conv3DBackpropFilterV2",j="Conv3DBackpropInputV2",st="Cos",pt="Cosh",ut="Cumprod",Ot="Cumsum",Bt="CropAndResize",wt="DenseBincount",Ct="DepthToSpace",Pt="DepthwiseConv2dNative",Wt="DepthwiseConv2dNativeBackpropFilter",Ht="DepthwiseConv2dNativeBackpropInput",Gt="Diag",Ve="Dilation2D",Vt="Dilation2DBackpropInput",Jt="Dilation2DBackpropFilter",Xt="Draw",Yt="RealDiv",Je="Einsum",qt="Elu",et="EluGrad",_t="Erf",At="Equal",te="Exp",ee="ExpandDims",Dt="Expm1",xt="FFT",Qt="Fill",se="FlipLeftRight",Ut="Floor",ne="FloorDiv",Et="FusedBatchNorm",ie="GatherV2",$t="GatherNd",vt="Greater",Xe="GreaterEqual",ys="Identity",Ye="IFFT",Zt="Imag",re="IsFinite",jt="IsInf",ae="IsNan",oe="LeakyRelu",le="Less",ue="LessEqual",he="LinSpace",ce="Log",de="Log1p",pe="LogicalAnd",fe="LogicalNot",me="LogicalOr",zt="LogicalXor",Nt="LogSoftmax",Tt="LRN",vs="LRNGrad",bs="Max",Ft="Maximum",ws="MaxPool",Mt="MaxPoolGrad",zs="MaxPool3D",Lt="MaxPool3DGrad",Cs="MaxPoolWithArgmax",St="Mean",qe="Min",ge="Minimum",ye="MirrorPad",ve="Mod",be="Multinomial",It="Multiply",_e="Neg",ts="NotEqual",es="NonMaxSuppressionV3",we="NonMaxSuppressionV4",ze="NonMaxSuppressionV5",As="OnesLike",ss="OneHot",Ce="Pack",kt="PadV2",Ae="Pow",De="Prelu",Se="Prod",Ie="RaggedGather",Re="RaggedRange",xe="RaggedTensorToTensor",Ee="Range",Ne="Real",Te="Reciprocal",Fe="Relu",Me="Reshape",Le="ResizeNearestNeighbor",ke="ResizeNearestNeighborGrad",Oe="ResizeBilinear",Be="ResizeBilinearGrad",is="Relu6",Pe="Reverse",We="Round",rs="Rsqrt",as="ScatterNd",Qe="TensorScatterUpdate",Ue="SearchSorted",os="Select",ls="Selu",$e="Slice",us="Sin",Ze="Sinh",hs="Sign",je="Sigmoid",Ke="Softplus",cs="Sqrt",ds="Sum",He="SpaceToBatchND",Ge="SplitV",Ds="Softmax",Ss="SparseFillEmptyRows",Is="SparseReshape",Rs="SparseSegmentMean",xs="SparseSegmentSum",Es="SparseToDense",Ns="SquaredDifference",Ts="Square",Fs="StaticRegexReplace",Ks="StridedSlice",Hs="StringNGrams",Ms="StringSplit",Ls="StringToHashBucketFast",Gs="Sub",Vs="Tan",Js="Tanh",ks="Tile",ct="TopK",Os="Transform",Bs="Transpose",ps="Unique",Ps="Unpack",Ws="UnsortedSegmentSum",fs="ZerosLike",d="Step",un="FromPixels",hn="RotateWithOffset",cn="_FusedMatMul",dn="FusedConv2D",pn="FusedDepthwiseConv2D"},14146:(I,Q,l)=>{"use strict";l.r(Q),l.d(Q,{prepareAndValidate:()=>r});var y=l(26674);function r(F,$){const A=F.shape.length,R=$.shape.length;if(A<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${A}.`);if(R<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${R}.`);if("int32"!==$.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${$.dtype}.`);if($.shape[R-1]>A)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${$.shape[R-1]} vs. ${A}`);if(0===(0,y.Ze)(F.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${F.shape}.`);const w=$.shape,M=w[w.length-1];let f=1;for(let H=0;H<w.length-1;++H)f*=w[H];const L=F.shape,W=w.slice();W.pop();let nt=1;for(let H=M;H<A;++H)nt*=L[H],W.push(L[H]);const S=[...(0,y.Ur)(F.shape).map(H=>H/nt),1].slice(0,M);return[W,f,nt,S]}},17731:(I,Q,l)=>{"use strict";l.r(Q),l.d(Q,{calculateShapes:()=>$,validateInput:()=>F,validateUpdateShape:()=>r});var y=l(26674);function r(A,R,w){const M=R.rank>1?R.shape[R.rank-1]:1,f=R.rank>1?R.rank-1:1,L=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${w.shape}, indices.shape: ${R.shape}, shape: ${A}, sliceDim: ${M}, and batchDim: ${f}.`;if(w.rank<f)throw new Error(L+` update.rank < ${f}. `);if(A.length<M+(w.rank-f))throw new Error(L+` Output shape length < ${M+(w.rank-f)}`);if(w.rank!==f+A.length-M)throw new Error(L+" update.rank != "+(f+A.length-M));for(let W=0;W<f;++W)if(w.shape[W]!==R.shape[W])throw new Error(L+` updates.shape[${W}] (${w.shape[W]}) != indices.shape[${W}] (${R.shape[W]}).`);for(let W=0;W<w.rank-f;++W)if(w.shape[W+f]!==A[W+M])throw new Error(L+` updates.shape[${W+f}] (${w.shape[W+f]}) != shape[${W+f}] (${A[W+f]})`)}function F(A,R,w){if(R.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${R.rank}.`);if(A.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${A.rank}.`);if("int32"!==R.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${R.dtype}`);if(w.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${w}`);if(0===w.length){if(0===R.size)throw new Error(`Indices specified for empty output. indices shape: ${R.shape}`);if(0===A.size)throw new Error(`Updates specified for empty output. updates shape: ${A.shape}`)}r(w,R,A)}function $(A,R,w){const M=R.shape.length,f=M>1?R.shape[M-1]:1,L=w.length;let W=1;for(let it=f;it<L;++it)W*=w[it];const nt=f<1?1:f;return{sliceRank:f,numUpdates:(0,y.Ze)(R.shape)/nt,sliceSize:W,strides:[...(0,y.Ur)(w.slice(0,f)),1],outputSize:(0,y.Ze)(w)}}},74042:(I,Q,l)=>{"use strict";l.d(Q,{DJ:()=>U,Fb:()=>H,ZI:()=>f,dv:()=>rt,ht:()=>W,kP:()=>nt,lh:()=>Z});var y=l(10467),r=l(41653),F=l(48814),A=l(58034),R=l(27669),w=l(52531),M=l(92357);function f(D){return new it(D)}function W(D){return new K(D)}function nt(D,h){return new ot(D,h)}function H(D,h=rt.FAIL){return new x(D,h)}class U{toArray(){var h=this;return(0,y.A)(function*(){const v=[];let j=yield h.next();for(;!j.done;)v.push(j.value),j=yield h.next();return v})()}toArrayForTest(){var h=this;return(0,y.A)(function*(){const v=h.prefetch(100),j=[];let st=yield v.next();for(;!st.done;)j.push(st.value),st=yield v.next();return j})()}resolveFully(){var h=this;return(0,y.A)(function*(){let v=yield h.next();for(;!v.done;)v=yield h.next()})()}resolveWhile(h){var v=this;return(0,y.A)(function*(){let j=yield v.next(),st=h(j.value);for(;!j.done&&st;)j=yield v.next(),st=h(j.value)})()}handleErrors(h){return new B(this,h)}filter(h){return new c(this,h)}map(h){return new T(this,h)}mapAsync(h){return new X(this,h)}serialMapAsync(h){return new X(this,h).serial()}flatmap(h){return new q(this,h)}forEachAsync(h){var v=this;return(0,y.A)(function*(){return v.map(h).resolveFully()})()}serialForEach(h){var v=this;return(0,y.A)(function*(){return v.serialMapAsync(h).resolveWhile(j=>!0===j)})()}rowMajorBatch(h,v=!0){return new C(this,h,v)}columnMajorBatch(h,v=!0,j=R.rN){return this.rowMajorBatch(h,v).map(pt=>(0,R.sy)(pt,j))}concatenate(h,v){return new ot(f([this,h]),v)}take(h){return h<0||null==h?this:new z(this,h)}skip(h){return h<0||null==h?this:new m(this,h)}prefetch(h){return new P(this,h)}shuffle(h,v){return new Y(this,h,v)}serial(){return new N(this)}}class it extends U{constructor(h){super(),this.items=h,this.trav=0}summary(){return`Array of ${this.items.length} items`}next(){var h=this;return(0,y.A)(function*(){if(h.trav>=h.items.length)return{value:null,done:!0};const v=h.items[h.trav];return h.trav++,{value:(0,A.G)(v),done:!1}})()}}class K extends U{constructor(h){super(),this.nextFn=h}summary(){return"Function call"}next(){var h=this;return(0,y.A)(function*(){try{return h.nextFn()}catch(v){throw v.message=`Error thrown while iterating through a dataset: ${v.message}`,v}})()}}class N extends U{constructor(h){super(),this.upstream=h,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){return h.upstream.next()})()}}class m extends U{constructor(h,v){super(),this.upstream=h,this.maxCount=v,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){for(;h.count++<h.maxCount;){const v=yield h.upstream.next();if(v.done)return v;r.ASo(v.value)}return h.upstream.next()})()}}class z extends U{constructor(h,v){super(),this.upstream=h,this.maxCount=v,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}next(){var h=this;return(0,y.A)(function*(){return h.count++>=h.maxCount?{value:null,done:!0}:h.upstream.next()})()}}class C extends U{constructor(h,v,j=!0){super(),this.upstream=h,this.batchSize=v,this.enableSmallLastBatch=j,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){const v=[];for(;v.length<h.batchSize;){const j=yield h.upstream.next();if(j.done)return h.enableSmallLastBatch&&v.length>0?{value:v,done:!1}:{value:null,done:!0};v.push(j.value)}return{value:v,done:!1}})()}}class c extends U{constructor(h,v){super(),this.upstream=h,this.predicate=v,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){for(;;){const v=yield h.upstream.next();if(v.done||h.predicate(v.value))return v;r.ASo(v.value)}})()}}class T extends U{constructor(h,v){super(),this.upstream=h,this.transform=v}summary(){return`${this.upstream.summary()} -> Map`}next(){var h=this;return(0,y.A)(function*(){const v=yield h.upstream.next();if(v.done)return{value:null,done:!0};const j=r.d_S.getTensorsInContainer(v.value),st=h.transform(v.value),pt=r.d_S.getTensorsInContainer(st);for(const ut of j)r.d_S.isTensorInList(ut,pt)||ut.dispose();return{value:st,done:!1}})()}}class B extends U{constructor(h,v){super(),this.upstream=h,this.handler=v,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){for(;;)try{return yield h.upstream.next()}catch(v){if(!h.handler(v))return{value:null,done:!0}}})()}}class X extends U{constructor(h,v){super(),this.upstream=h,this.transform=v}summary(){return`${this.upstream.summary()} -> AsyncMap`}next(){var h=this;return(0,y.A)(function*(){const v=yield h.upstream.next();if(v.done)return{value:null,done:!0};const j=r.d_S.getTensorsInContainer(v.value),st=yield h.transform(v.value),pt=r.d_S.getTensorsInContainer(st);for(const ut of j)r.d_S.isTensorInList(ut,pt)||ut.dispose();return{value:st,done:!1}})()}}class Z extends U{constructor(){super(),this.outputQueue=new w.g,this.lastRead=Promise.resolve({value:null,done:!1})}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}serialNext(){var h=this;return(0,y.A)(function*(){for(;0===h.outputQueue.length();)if(!(yield h.pump()))return{value:null,done:!0};return{value:h.outputQueue.shift(),done:!1}})()}}class q extends Z{constructor(h,v){super(),this.upstream=h,this.transform=v}summary(){return`${this.upstream.summary()} -> Flatmap`}pump(){var h=this;return(0,y.A)(function*(){const v=yield h.upstream.next();if(v.done)return!1;const j=r.d_S.getTensorsInContainer(v.value),st=h.transform(v.value),pt=r.d_S.getTensorsInContainer(st);h.outputQueue.pushAll(st);for(const ut of j)r.d_S.isTensorInList(ut,pt)||ut.dispose();return!0})()}}class ot extends U{constructor(h,v){super(),this.baseErrorHandler=v,this.lastRead=null,this.iterator=null,this.moreIterators=h}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.readFromChain(h.lastRead),h.lastRead})()}readFromChain(h){var v=this;return(0,y.A)(function*(){if(yield h,null==v.iterator){const st=yield v.moreIterators.next();if(st.done)return{value:null,done:!0};v.iterator=st.value,null!=v.baseErrorHandler&&(v.iterator=v.iterator.handleErrors(v.baseErrorHandler))}const j=yield v.iterator.next();return j.done?(v.iterator=null,v.readFromChain(h)):j})()}}var rt=function(D){return D[D.FAIL=0]="FAIL",D[D.SHORTEST=1]="SHORTEST",D[D.LONGEST=2]="LONGEST",D}(rt||{});class x extends U{constructor(h,v=rt.FAIL){super(),this.iterators=h,this.mismatchMode=v,this.count=0,this.currentPromise=null}summary(){return"{TODO: fill in upstream of zip summaries} -> Zip"}nextState(h){var v=this;return(0,y.A)(function*(){yield h;let j=0,st=0;const ut=yield(0,R.te)(v.iterators,function pt(Ot){return Ot instanceof U?{value:Ot.next().then(wt=>(j++,wt.done&&st++,wt.value)),recurse:!1}:{value:null,recurse:!0}});if(j===st)return{value:null,done:!0};if(st>0)switch(v.mismatchMode){case rt.FAIL:throw new Error(`Zipped streams should have the same length. Mismatched at element ${v.count}.`);case rt.SHORTEST:return{value:null,done:!0}}return v.count++,{value:ut,done:!1}})()}next(){var h=this;return(0,y.A)(function*(){return h.currentPromise=h.nextState(h.currentPromise),h.currentPromise})()}}class P extends U{constructor(h,v){super(),this.upstream=h,this.bufferSize=v,this.buffer=new M.N(v)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const h=this.upstream.next();this.buffer.push(h)}}next(){return this.refill(),this.buffer.shift()}}class Y extends P{constructor(h,v,j){super(h,v),this.upstream=h,this.windowSize=v,this.upstreamExhausted=!1,this.random=F.alea(j||r.ZSL.now().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}next(){var h=this;return(0,y.A)(function*(){return h.lastRead=h.lastRead.then(()=>h.serialNext()),h.lastRead})()}randomInt(h){return Math.floor(this.random()*h)}chooseIndex(){return this.randomInt(this.buffer.length())}serialNext(){var h=this;return(0,y.A)(function*(){for(h.upstreamExhausted||h.refill();!h.buffer.isEmpty();){const v=h.chooseIndex(),j=yield h.buffer.shuffleExcise(v);if(!j.done)return h.refill(),j;h.upstreamExhausted=!0}return{value:null,done:!0}})()}}},27669:(I,Q,l)=>{"use strict";l.d(Q,{Bl:()=>F,mf:()=>W,rN:()=>w,sy:()=>A,te:()=>M,xZ:()=>L});var y=l(10467),r=l(41653);function F(S,H){return $(S,H)}function $(S,H,U=new Map,it=new Set){if(null==S)return null;if("function"==typeof Blob&&S instanceof Blob)return S.slice();if(it.has(S))throw new Error("Circular references are not supported.");if(U.has(S))return U.get(S);const K=H(S);if(K.recurse&&null!==K.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(K.recurse){if(L(S)){const N=Array.isArray(S)?[]:{};it.add(S);for(const m in S){const C=$(S[m],H,U,it);N[m]=C}return it.delete(S),S.__proto__&&(N.__proto__=S.__proto__),N}throw new Error(`Can't recurse into non-iterable type: ${S}`)}return U.set(S,K.value),K.value}function A(S,H=w){return R(S,H)}function R(S,H,U=new Set){const it=S[0];if(U.has(it))throw new Error("Circular references are not supported.");const K=H(S);if(K.recurse&&null!==K.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(K.recurse){if(L(it)){const N=Array.isArray(it)?[]:{};U.add(it);for(const m in it){const C=R(S.map(c=>c[m]),H,U);N[m]=C}return U.delete(it),N}throw new Error(`Can't recurse into non-iterable type: ${it}`)}return K.value}function w(S){return null===S?null:L(S[0])?{value:null,recurse:!0}:{value:S,recurse:!1}}function M(S,H){return f.apply(this,arguments)}function f(){return(f=(0,y.A)(function*(S,H){const U=new Map;$(S,H,U);for(const K of Array.from(U.keys())){const N=U.get(K);if(r.ZSL.isPromise(N)){const m=yield N;U.set(K,m)}}return $(S,H,U)})).apply(this,arguments)}function L(S){let H=!1;if(r._K2().get("IS_BROWSER"))H=S instanceof TextDecoder;else{const{StringDecoder:U}=l(80551);H=S instanceof U}return null!=S&&!ArrayBuffer.isView(S)&&(Array.isArray(S)||"object"==typeof S&&!(S instanceof r.qYS)&&!(S instanceof Promise)&&!H)}function W(S){return null==S||function nt(S){return null===S||"object"!=typeof S&&"function"!=typeof S}(S)||Array.isArray(S)||"object"==typeof S&&S instanceof r.qYS||r.ZSL.isTypedArray(S)}},91806:(I,Q,l)=>{"use strict";l.d(Q,{m:()=>A,p:()=>R});var y=l(41653),r=l(29887),F=l(42946),$=l(22919);let A=(()=>{class w extends $.Wd{constructor(f){if(super({dtype:f.dtype,name:null!=f.name?f.name:(0,r.v)("input").toString()}),null==f.batchSize&&(f.batchSize=null),null==f.sparse&&(f.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=f.sparse,null!=f.inputShape&&null!=f.batchInputShape)throw new F.Qp("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let L=f.batchInputShape;if(null==L){if(null==f.inputShape)throw new F.Qp("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");L=[f.batchSize].concat(f.inputShape)}else if(null!=f.batchSize)throw new F.Qp("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const W=f.dtype||"float32";this.batchInputShape=L,this.dtype=W,this.inputSpec=[{shape:L}];const nt=new $.Ar(this.dtype,this.batchInputShape,this,[],{},this.name);nt.nodeIndex=0,nt.tensorIndex=0,new $.bP({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[nt],outputTensors:[nt],inputMasks:[null],outputMasks:[null],inputShapes:[L],outputShapes:[L]})}apply(f,L){throw new F.Qp(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}return w.className="InputLayer",w})();function R(w){if(null==w.batchShape&&null==w.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=w.batchShape&&null!=w.shape)throw new F.Qp("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let M=w.batchShape;null!=w.shape&&null==M&&(M=[null].concat(w.shape));let f=w.dtype;return null==f&&(f="float32"),new A({batchInputShape:M,name:w.name,dtype:f,sparse:w.sparse}).inboundNodes[0].outputTensors[0]}y.JFn.registerClass(A)},48631:(I,Q,l)=>{"use strict";l.d(Q,{Gx:()=>m});var y=l(10467),r=l(41653),F=l(29887),$=l(91806),A=l(22919),R=l(31542),w=l(42946),M=l(53340),f=l(24503),W=(l(13425),l(71936));let m=(()=>{class z extends R.Gw{constructor(c){if(super({inputs:[],outputs:[]}),c=c||{},this.trainable=!0,this.built=!1,this.name=null!=c.name?c.name:(0,F.v)("sequential_"),null!=c.layers)for(const T of c.layers)this.add(T)}checkShape(c){if(c.inboundNodes[0].outputTensors[0].shape.some(B=>B<0))throw new w.Qp(`Negative dimension size caused by adding layer ${c.name} with input shape [${c.inboundNodes[0].inputTensors[0].shape}]`)}add(c){const T=c instanceof z||c instanceof R.Gw;let B;if(T){if(B=c,1!==B.outputs.length)throw new w.Qp("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==B.inputs.length)throw new w.Qp("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===c.inboundNodes.length){if(null==c.batchInputShape)throw new w.Qp("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const X=(0,$.p)({batchShape:c.batchInputShape,dtype:c.dtype,name:c.name+"_input"});c.apply(X)}if(T)this.outputs=B.outputs,this.inputs=B.inputs;else{if(1!==c.inboundNodes.length)throw new w.Qp(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${c.name} which has ${c.inboundNodes.length} pre-existing inbound connections.`);if(1!==c.inboundNodes[0].outputTensors.length)throw new w.Qp("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(c),this.outputs=[c.inboundNodes[0].outputTensors[0]],this.inputs=(0,A.X6)(this.outputs[0])}this.inboundNodes=[],new A.bP({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:f.fD(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(X=>X.shape),outputShapes:this.outputs[0].shape})}else{const X=c.apply(this.outputs[0]);if(Array.isArray(X))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(c),this.outputs=[X],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(c),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const c=this.layers.length-1;this.layers[c].outboundNodes=[],this.outputs=[this.layers[c].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(c,T){return null==this.model&&this.build(),this.model.call(c,T)}build(c){if((0,W.U$)(c),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new R.Gw({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(c,T,B=console.log){this.built||this.build(),super.summary(c,T,B)}setWeights(c){null==this.model&&this.build(),this.model.setWeights(c)}evaluate(c,T,B={}){if(!this.built)throw new w.bu("The model needs to be compiled before being used.");return this.model.evaluate(c,T,B)}evaluateDataset(c,T){var B=this;return(0,y.A)(function*(){if(!B.built)throw new w.bu("The model needs to be compiled before being used.");return B.model.evaluateDataset(c,T)})()}predict(c,T={}){return null==this.model&&this.build(),this.model.predict(c,T)}predictOnBatch(c){return null==this.model&&this.build(),this.model.predictOnBatch(c)}compile(c){this.build(),this.model.compile(c),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(c){this.model.optimizer=c}fit(c,T){var B=this;return(0,y.A)(function*(X,Z,q={}){if(!B.built)throw new w.bu("The model needs to be compiled before being used.");return B.model.fit(X,Z,q)}).apply(this,arguments)}fitDataset(c,T){var B=this;return(0,y.A)(function*(){if(!B.built)throw new w.bu("The model needs to be compiled before being used.");return B.model.fitDataset(c,T)})()}trainOnBatch(c,T){var B=this;return(0,y.A)(function*(){return B.model.trainOnBatch(c,T)})()}static fromConfig(c,T,B={},X=!1){let Z,q={};if(T instanceof Array){if(null==T[0].className||"Merge"===T[0].className)throw new w.Qp("Legacy serialization format not supported yet.");Z=T}else r.ZSL.assert(null!=T.layers,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),Z=T.layers,delete T.layers,q=T;const ot=new c(q);if(!(ot instanceof z))throw new w.EH(`Sequential.fromConfig called on non-Sequential input: ${ot}`);for(const rt of Z){const P=(0,M.i)(rt,void 0,X);X&&P.setFastWeightInitDuringBuild(!0),ot.add(P)}return ot}set stopTraining(c){if(null==this.model)throw new w.Qp("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=c}get stopTraining(){if(null==this.model)throw new w.Qp("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const c=[];for(const T of this.layers){const B={};B.className=T.getClassName(),B.config=T.getConfig(),c.push(B)}return{name:this.name,layers:c}}}return z.className="Sequential",z})();r.JFn.registerClass(m)},13425:(I,Q,l)=>{"use strict";l.d(Q,{M:()=>$,w:()=>F});var y=l(24503);function r(A,R,w){return("inboundNodes"===A||"outputLayers"===A||"inputLayers"===A)&&0===R&&"string"==typeof w}function F(A,R){if(null===A)return null;if("string"==typeof A)return y.Cb(A);if("number"==typeof A||"boolean"==typeof A)return A;if(A instanceof Array){const w=[],M=A.length;for(let f=0;f<M;++f){const L=A[f];r(R,f,L)?w.push(L):w.push(F(L,R))}return w}{const w={};for(const M of Object.keys(A)){const f=A[M];if("name"===M&&"string"==typeof f)w[M]=f;else{const L=y.Cb(M);w[L]=F(f,L)}}return w}}function $(A,R){if(null==A)return null;if("string"==typeof A)return y.uc(A);if("number"==typeof A||"boolean"==typeof A)return A;if(A instanceof Array){const w=[],M=A.length;for(let f=0;f<M;++f){const L=A[f];r(R,f,L)?w.push(L):w.push($(L,R))}return w}{const w={};for(const M of Object.keys(A)){const f=A[M];w[y.uc(M)]="name"!==M&&"className"!==M||"string"!=typeof f?$(f,M):f}return w}}},48814:(I,Q,l)=>{var y=l(2495),r=l(57850),F=l(85704),$=l(88114),A=l(79040),R=l(84478),w=l(97454);w.alea=y,w.xor128=r,w.xorwow=F,w.xorshift7=$,w.xor4096=A,w.tychei=R,I.exports=w},10467:(I,Q,l)=>{"use strict";function y(F,$,A,R,w,M,f){try{var L=F[M](f),W=L.value}catch(nt){return void A(nt)}L.done?$(W):Promise.resolve(W).then(R,w)}function r(F){return function(){var $=this,A=arguments;return new Promise(function(R,w){var M=F.apply($,A);function f(W){y(M,R,w,f,L,"next",W)}function L(W){y(M,R,w,f,L,"throw",W)}f(void 0)})}}l.d(Q,{A:()=>r})}},ln={};function G(I){var Q=ln[I];if(void 0!==Q)return Q.exports;var l=ln[I]={id:I,loaded:!1,exports:{}};return on[I].call(l.exports,l,l.exports,G),l.loaded=!0,l.exports}G.m=on,G.x=()=>{var I=G.O(void 0,[2296],()=>G(18633));return G.O(I)},G.amdD=function(){throw new Error("define cannot be used indirect")},G.amdO={},I=[],G.O=(Q,l,y,r)=>{if(!l){var $=1/0;for(F=0;F<I.length;F++){for(var[l,y,r]=I[F],A=!0,R=0;R<l.length;R++)(!1&r||$>=r)&&Object.keys(G.O).every(nt=>G.O[nt](l[R]))?l.splice(R--,1):(A=!1,r<$&&($=r));if(A){I.splice(F--,1);var w=y();void 0!==w&&(Q=w)}}return Q}r=r||0;for(var F=I.length;F>0&&I[F-1][2]>r;F--)I[F]=I[F-1];I[F]=[l,y,r]},G.n=I=>{var Q=I&&I.__esModule?()=>I.default:()=>I;return G.d(Q,{a:Q}),Q},G.d=(I,Q)=>{for(var l in Q)G.o(Q,l)&&!G.o(I,l)&&Object.defineProperty(I,l,{enumerable:!0,get:Q[l]})},G.f={},G.e=I=>Promise.all(Object.keys(G.f).reduce((Q,l)=>(G.f[l](I,Q),Q),[])),G.u=I=>I+"."+{2296:"653b69abbea77bef",2719:"8f1da66d3a47461c"}[I]+".js",G.miniCssF=I=>{},G.o=(I,Q)=>Object.prototype.hasOwnProperty.call(I,Q),G.r=I=>{typeof Symbol<"u"&&Symbol.toStringTag&&Object.defineProperty(I,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(I,"__esModule",{value:!0})},G.nmd=I=>(I.paths=[],I.children||(I.children=[]),I),(()=>{var I;G.tt=()=>(void 0===I&&(I={createScriptURL:Q=>Q},typeof trustedTypes<"u"&&trustedTypes.createPolicy&&(I=trustedTypes.createPolicy("angular#bundler",I))),I)})(),G.tu=I=>G.tt().createScriptURL(I),G.p="",(()=>{var I={8633:1};G.f.i=(r,F)=>{I[r]||importScripts(G.tu(G.p+G.u(r)))};var l=self.webpackChunkapp=self.webpackChunkapp||[],y=l.push.bind(l);l.push=r=>{var[F,$,A]=r;for(var R in $)G.o($,R)&&(G.m[R]=$[R]);for(A&&A(G);F.length;)I[F.pop()]=1;y(r)}})(),(()=>{var I=G.x;G.x=()=>G.e(2296).then(I)})(),G.x()})();